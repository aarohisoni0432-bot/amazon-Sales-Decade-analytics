{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0921d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33165, 34)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project = Path.cwd()\n",
    "data_raw = project.parent / \"data_raw\"\n",
    "\n",
    "file_2015 = data_raw / \"amazon_india_2015.csv\"\n",
    "df = pd.read_csv(file_2015, low_memory=False)\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b68d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17288\\829849314.py:7: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  col = pd.to_datetime(col, errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(3252)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEANING 1: Clean order_date\n",
    "\n",
    "def clean_order_date(col):\n",
    "    # Convert to datetime\n",
    "    # errors='coerce' converts bad dates to NaT\n",
    "    # dayfirst=True handles DD/MM/YYYY formats\n",
    "    col = pd.to_datetime(col, errors='coerce', dayfirst=True)\n",
    "    return col\n",
    "\n",
    "df['order_date_clean'] = clean_order_date(df['order_date'])\n",
    "\n",
    "# Check how many invalid dates became NaT (missing)\n",
    "df['order_date_clean'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a8871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bad dates: 3252\n",
      "\n",
      "Top 30 most common raw strings among bad dates:\n",
      "order_date\n",
      "22/12/2015    12\n",
      "10/07/2015    12\n",
      "12/05/2015    11\n",
      "10/08/2015    11\n",
      "03/07/2015    11\n",
      "24-12-2015    11\n",
      "13/10/2015    11\n",
      "12/10/2015    11\n",
      "03/12/2015    10\n",
      "09/05/2015    10\n",
      "07/09/2015    10\n",
      "01/04/2015    10\n",
      "12/06/2015     9\n",
      "14/10/2015     9\n",
      "13/09/2015     9\n",
      "11/04/2015     9\n",
      "12/12/2015     9\n",
      "10/01/2015     9\n",
      "25-07-2015     9\n",
      "05/10/2015     9\n",
      "06/09/2015     9\n",
      "10/11/2015     9\n",
      "21/10/2015     9\n",
      "02/09/2015     9\n",
      "10-11-2015     9\n",
      "11/23/2015     9\n",
      "29-04-2015     9\n",
      "07/06/2015     8\n",
      "01/03/2015     8\n",
      "31-08-2015     8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show sample raw date strings which produced NaT\n",
    "bad_mask = df['order_date_clean'].isna()\n",
    "bad_dates = df.loc[bad_mask, 'order_date'].astype(str)\n",
    "\n",
    "print(\"Total bad dates:\", bad_dates.shape[0])\n",
    "print(\"\\nTop 30 most common raw strings among bad dates:\")\n",
    "print(bad_dates.value_counts().head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df405be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to attempt fallback parse: 3252\n",
      "Recovered with dayfirst=False: 1307\n",
      "Recovered with yearfirst=True: 1192\n",
      "Total recovered in order_date_clean2: 2499\n",
      "Remaining missing after fallback attempts: 753\n",
      "Final missing after combining: 753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17288\\676345187.py:6: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df.loc[mask_na, 'order_date_clean2'] = pd.to_datetime(df.loc[mask_na, 'order_date'],\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17288\\676345187.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df.loc[mask_still, 'order_date_clean2'] = pd.to_datetime(df.loc[mask_still, 'order_date'],\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17288\\676345187.py:17: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df.loc[mask_still, 'order_date_clean2'] = pd.to_datetime(df.loc[mask_still, 'order_date'],\n"
     ]
    }
   ],
   "source": [
    "# attempt fallback parsing for remaining NaT rows\n",
    "mask_na = df['order_date_clean'].isna()\n",
    "print(\"Rows to attempt fallback parse:\", mask_na.sum())\n",
    "\n",
    "# Try parsing with dayfirst=False first\n",
    "df.loc[mask_na, 'order_date_clean2'] = pd.to_datetime(df.loc[mask_na, 'order_date'],\n",
    "                                                       errors='coerce',\n",
    "                                                       dayfirst=False,\n",
    "                                                       infer_datetime_format=True,\n",
    "                                                       yearfirst=False)\n",
    "\n",
    "recovered1 = df['order_date_clean2'].notna().sum()\n",
    "print(\"Recovered with dayfirst=False:\", int(recovered1))\n",
    "\n",
    "# For any still missing, try yearfirst=True (handles YYYY/MM/DD)\n",
    "mask_still = df['order_date_clean2'].isna() & df['order_date_clean'].isna()\n",
    "df.loc[mask_still, 'order_date_clean2'] = pd.to_datetime(df.loc[mask_still, 'order_date'],\n",
    "                                                         errors='coerce',\n",
    "                                                         infer_datetime_format=True,\n",
    "                                                         yearfirst=True)\n",
    "\n",
    "recovered2 = df['order_date_clean2'].notna().sum() - recovered1\n",
    "print(\"Recovered with yearfirst=True:\", int(recovered2))\n",
    "\n",
    "# Final counts\n",
    "total_recovered = df['order_date_clean2'].notna().sum()\n",
    "still_missing = df['order_date_clean'].isna().sum() - total_recovered\n",
    "print(\"Total recovered in order_date_clean2:\", int(total_recovered))\n",
    "print(\"Remaining missing after fallback attempts:\", int(still_missing))\n",
    "\n",
    "# If order_date_clean2 has values, fill original clean column\n",
    "df['order_date_clean'] = df['order_date_clean'].combine_first(df['order_date_clean2'])\n",
    "\n",
    "print(\"Final missing after combining:\", int(df['order_date_clean'].isna().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f269409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total still-missing rows: 753\n",
      "\n",
      "Top 40 most common raw strings among remaining bad dates:\n",
      "\n",
      "order_date\n",
      "22/12/2015    12\n",
      "13/10/2015    11\n",
      "13/09/2015     9\n",
      "21/10/2015     9\n",
      "14/10/2015     9\n",
      "22/10/2015     8\n",
      "27/04/2015     7\n",
      "30/07/2015     7\n",
      "26/09/2015     7\n",
      "26/05/2015     7\n",
      "20/12/2015     7\n",
      "16/12/2015     7\n",
      "26/10/2015     7\n",
      "26/06/2015     6\n",
      "17/09/2015     6\n",
      "27/10/2015     6\n",
      "21/11/2015     6\n",
      "17/07/2015     6\n",
      "29/01/2015     6\n",
      "25/03/2015     6\n",
      "21/03/2015     6\n",
      "20/05/2015     6\n",
      "19/09/2015     6\n",
      "26/12/2015     6\n",
      "24/11/2015     6\n",
      "25/12/2015     6\n",
      "27/12/2015     6\n",
      "23/10/2015     6\n",
      "28/11/2015     5\n",
      "23/11/2015     5\n",
      "23/07/2015     5\n",
      "21/06/2015     5\n",
      "15/06/2015     5\n",
      "16/07/2015     5\n",
      "17/06/2015     5\n",
      "26/08/2015     5\n",
      "15/07/2015     5\n",
      "19/07/2015     5\n",
      "14/01/2015     5\n",
      "27/02/2015     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A: show top raw strings that remain missing after previous attempts\n",
    "bad_mask = df['order_date_clean'].isna()\n",
    "bad_dates = df.loc[bad_mask, 'order_date'].astype(str)\n",
    "\n",
    "print(\"Total still-missing rows:\", bad_dates.shape[0])\n",
    "print(\"\\nTop 40 most common raw strings among remaining bad dates:\\n\")\n",
    "print(bad_dates.value_counts().head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2902a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed by regex+dateutil: 753\n",
      "Final missing after regex+dateutil attempt: 0\n"
     ]
    }
   ],
   "source": [
    "# B: aggressive fallback using regex extraction + dateutil\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "def extract_date_like(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    # remove common noisy words\n",
    "    s_clean = re.sub(r'(?i)\\b(approx|approx\\.|around|est|estimated|tbd|unknown|na|n/a|not available)\\b', ' ', s)\n",
    "    s_clean = s_clean.replace(',', ' ').replace(';', ' ').replace('.', ' ')\n",
    "    # find first date-like substring (several common patterns)\n",
    "    patterns = [\n",
    "        r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}',    # 12-05-2019 or 12/05/2019\n",
    "        r'\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}',      # 2019-05-12 or 2019/5/12\n",
    "        r'\\d{1,2}\\s+[A-Za-z]{3,9}\\s+\\d{4}',  # 12 Jan 2019\n",
    "        r'[A-Za-z]{3,9}\\s+\\d{1,2},?\\s+\\d{4}',# Jan 12 2019 or January 12, 2019\n",
    "        r'\\d{4}'                             # year only (will parse to 1 Jan of that year)\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, s_clean)\n",
    "        if m:\n",
    "            return m.group(0)\n",
    "    return s_clean  # as last resort, try the whole cleaned string\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if s is None or s.strip()==\"\":\n",
    "        return None\n",
    "    try:\n",
    "        # parser.parse with dayfirst=True to prefer D/M/Y where ambiguous\n",
    "        dt = parser.parse(s, dayfirst=True, fuzzy=True)\n",
    "        return pd.to_datetime(dt)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Apply only to still-missing rows\n",
    "mask = df['order_date_clean'].isna()\n",
    "candidates = df.loc[mask, 'order_date'].astype(str)\n",
    "\n",
    "# extract then parse\n",
    "extracted = candidates.map(extract_date_like)\n",
    "parsed = extracted.map(try_parse_date)\n",
    "\n",
    "# How many parsed?\n",
    "num_parsed = parsed.notna().sum()\n",
    "print(\"Parsed by regex+dateutil:\", int(num_parsed))\n",
    "\n",
    "# Fill into order_date_clean where parsed success\n",
    "df.loc[mask, 'order_date_clean'] = df.loc[mask, 'order_date_clean'].combine_first(parsed)\n",
    "\n",
    "print(\"Final missing after regex+dateutil attempt:\", int(df['order_date_clean'].isna().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c8f18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    123614.29\n",
       "1     54731.86\n",
       "2     97644.25\n",
       "3     21947.26\n",
       "4     54731.86\n",
       "5    131194.65\n",
       "6     86987.64\n",
       "7     32169.01\n",
       "8     40264.16\n",
       "9     54731.86\n",
       "Name: original_price_clean, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEANING 2: Clean original_price_inr\n",
    "\n",
    "def clean_price(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    \n",
    "    x = str(x).strip()\n",
    "    \n",
    "    # Remove currency symbols and commas\n",
    "    x = x.replace(\"₹\", \"\").replace(\",\", \"\").strip()\n",
    "    \n",
    "    # Handle non-numeric text cases\n",
    "    bad_values = [\"price on request\", \"not available\", \"na\", \"n/a\", \"-\", \"\", \"unknown\"]\n",
    "    if x.lower() in bad_values:\n",
    "        return None\n",
    "\n",
    "    # Try converting to float\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['original_price_clean'] = df['original_price_inr'].apply(clean_price)\n",
    "\n",
    "df['original_price_clean'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b8e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(987)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_price_clean'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f07719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_prime_member_clean</th>\n",
       "      <th>is_festival_sale_clean</th>\n",
       "      <th>is_prime_eligible_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_prime_member_clean  is_festival_sale_clean  is_prime_eligible_clean\n",
       "0                  False                    True                     True\n",
       "1                  False                   False                     True\n",
       "2                  False                    True                     True\n",
       "3                  False                   False                     True\n",
       "4                  False                   False                     True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEANING 3: Boolean columns (Yes/No/Y/N/1/0 → True/False)\n",
    "\n",
    "def clean_bool(x):\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    x = str(x).strip().lower()\n",
    "    return x in [\"yes\", \"y\", \"1\", \"true\"]\n",
    "\n",
    "bool_columns = ['is_prime_member', 'is_festival_sale', 'is_prime_eligible']\n",
    "\n",
    "for col in bool_columns:\n",
    "    df[col + \"_clean\"] = df[col].apply(clean_bool)\n",
    "\n",
    "df[[col + \"_clean\" for col in bool_columns]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d43c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows examined: 33165\n",
      "Parsed numeric ratings: 23196\n",
      "Missing after cleaning: 9969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>customer_rating_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4/5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0 stars</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5.0/5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4.5 stars</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3.5/5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3/5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>4.0 stars</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>4.5/5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_rating  customer_rating_clean\n",
       "0               5.0                    5.0\n",
       "1               4.5                    4.5\n",
       "2               NaN                    NaN\n",
       "3               3.0                    3.0\n",
       "4               4.0                    4.0\n",
       "6               3.5                    3.5\n",
       "13              4/5                    4.0\n",
       "16        5.0 stars                    5.0\n",
       "62          5.0/5.0                    5.0\n",
       "67        4.5 stars                    4.5\n",
       "70          3.5/5.0                    3.5\n",
       "94              3/5                    3.0\n",
       "133               4                    4.0\n",
       "260       4.0 stars                    4.0\n",
       "270         4.5/5.0                    4.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEANING 4: customer_rating normalization\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_rating_val(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    # common non-rating markers\n",
    "    if s in [\"na\", \"n/a\", \"nr\", \"no rating\", \"-\", \"none\", \"unknown\", \"not rated\"]:\n",
    "        return np.nan\n",
    "\n",
    "    # \"4 stars\" -> 4\n",
    "    m = re.match(r'^(\\d+(\\.\\d+)?)\\s*stars?$', s)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(1))\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # \"3/5\" or \"2.5/5.0\" -> take numerator\n",
    "    if '/' in s:\n",
    "        parts = s.split('/')\n",
    "        try:\n",
    "            val = float(parts[0])\n",
    "            return val\n",
    "        except:\n",
    "            # maybe string like \"Rated 4 out of 5\"\n",
    "            pass\n",
    "\n",
    "    # strings like \"rated 4 out of 5\"\n",
    "    m = re.search(r'(\\d+(\\.\\d+)?)\\s*(?:out of|/)\\s*\\d+', s)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(1))\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # plain numeric\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply to customer_rating\n",
    "df['customer_rating_clean'] = df['customer_rating'].apply(clean_rating_val)\n",
    "\n",
    "# Quick checks\n",
    "total = len(df)\n",
    "parsed = df['customer_rating_clean'].notna().sum()\n",
    "missing_after = df['customer_rating_clean'].isna().sum()\n",
    "\n",
    "print(f\"Total rows examined: {total}\")\n",
    "print(f\"Parsed numeric ratings: {parsed}\")\n",
    "print(f\"Missing after cleaning: {missing_after}\")\n",
    "\n",
    "# show a few examples side-by-side for manual inspection\n",
    "df[['customer_rating', 'customer_rating_clean']].drop_duplicates().head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b585de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_city_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allahabad</td>\n",
       "      <td>allahabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kolkata</td>\n",
       "      <td>kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ludhiana</td>\n",
       "      <td>ludhiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lucknow</td>\n",
       "      <td>lucknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>jaipur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>bhubaneswar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pune</td>\n",
       "      <td>pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kochi</td>\n",
       "      <td>kochi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_city customer_city_clean\n",
       "0         Mumbai              mumbai\n",
       "1      Allahabad           allahabad\n",
       "2         Mumbai              mumbai\n",
       "3        Kolkata             kolkata\n",
       "4       Ludhiana            ludhiana\n",
       "5          Delhi               delhi\n",
       "6        Lucknow             lucknow\n",
       "7         Jaipur              jaipur\n",
       "8          Delhi               delhi\n",
       "9    Bhubaneswar         bhubaneswar\n",
       "10     Ahmedabad           ahmedabad\n",
       "11     Bangalore           bangalore\n",
       "12         Delhi               delhi\n",
       "13        Mumbai              mumbai\n",
       "14     Bangalore           bangalore\n",
       "15          Pune                pune\n",
       "16         Kochi               kochi\n",
       "17       Chennai             chennai\n",
       "18       Chennai             chennai\n",
       "19        Mumbai              mumbai"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLEANING 5: Normalize customer_city\n",
    "\n",
    "def clean_city(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    x = str(x).strip().lower()\n",
    "    \n",
    "    # Replace slashes with space\n",
    "    x = x.replace(\"/\", \" \")\n",
    "    \n",
    "    # Fix common city variants\n",
    "    replacements = {\n",
    "        \"bengaluru\": \"bangalore\",\n",
    "        \"bengaluru bangalore\": \"bangalore\",\n",
    "        \"bangalore bengaluru\": \"bangalore\",\n",
    "        \"bombay\": \"mumbai\",\n",
    "        \"new delhi\": \"delhi\",\n",
    "    }\n",
    "    \n",
    "    # Direct replacement if exact match\n",
    "    if x in replacements:\n",
    "        return replacements[x]\n",
    "    \n",
    "    # Partial replacement\n",
    "    for old, new in replacements.items():\n",
    "        if old in x:\n",
    "            return new\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    x = \" \".join(x.split())\n",
    "    \n",
    "    return x\n",
    "\n",
    "df['customer_city_clean'] = df['customer_city'].apply(clean_city)\n",
    "\n",
    "df[['customer_city', 'customer_city_clean']].head(20)\n",
    "# CLEANING 5: Normalize customer_city\n",
    "\n",
    "def clean_city(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    x = str(x).strip().lower()\n",
    "    \n",
    "    # Replace slashes with space\n",
    "    x = x.replace(\"/\", \" \")\n",
    "    \n",
    "    # Fix common city variants\n",
    "    replacements = {\n",
    "        \"bengaluru\": \"bangalore\",\n",
    "        \"bengaluru bangalore\": \"bangalore\",\n",
    "        \"bangalore bengaluru\": \"bangalore\",\n",
    "        \"bombay\": \"mumbai\",\n",
    "        \"new delhi\": \"delhi\",\n",
    "    }\n",
    "    \n",
    "    # Direct replacement if exact match\n",
    "    if x in replacements:\n",
    "        return replacements[x]\n",
    "    \n",
    "    # Partial replacement\n",
    "    for old, new in replacements.items():\n",
    "        if old in x:\n",
    "            return new\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    x = \" \".join(x.split())\n",
    "    \n",
    "    return x\n",
    "\n",
    "df['customer_city_clean'] = df['customer_city'].apply(clean_city)\n",
    "\n",
    "df[['customer_city', 'customer_city_clean']].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb6c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (33165, 42)\n",
      "\n",
      "Data types:\n",
      "object            24\n",
      "float64            9\n",
      "int64              4\n",
      "bool               3\n",
      "datetime64[ns]     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing counts for key cleaned cols:\n",
      "order_date_clean              0\n",
      "original_price_clean        987\n",
      "is_prime_member_clean         0\n",
      "is_festival_sale_clean        0\n",
      "is_prime_eligible_clean       0\n",
      "customer_rating_clean      9969\n",
      "customer_city_clean           0\n",
      "dtype: int64\n",
      "shape: (33165, 42)\n",
      "\n",
      "Data types:\n",
      "object            24\n",
      "float64            9\n",
      "int64              4\n",
      "bool               3\n",
      "datetime64[ns]     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing counts for key cleaned cols:\n",
      "order_date_clean              0\n",
      "original_price_clean        987\n",
      "is_prime_member_clean         0\n",
      "is_festival_sale_clean        0\n",
      "is_prime_eligible_clean       0\n",
      "customer_rating_clean      9969\n",
      "customer_city_clean           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A1 - quick info\n",
    "print(\"shape:\", df.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# show nulls in important cleaned columns\n",
    "cols_check = [\n",
    "  'order_date_clean','original_price_clean',\n",
    "  'is_prime_member_clean','is_festival_sale_clean','is_prime_eligible_clean',\n",
    "  'customer_rating_clean','customer_city_clean'\n",
    "]\n",
    "print(\"\\nMissing counts for key cleaned cols:\")\n",
    "print(df[cols_check].isna().sum())\n",
    "# A1 - quick info\n",
    "print(\"shape:\", df.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# show nulls in important cleaned columns\n",
    "cols_check = [\n",
    "  'order_date_clean','original_price_clean',\n",
    "  'is_prime_member_clean','is_festival_sale_clean','is_prime_eligible_clean',\n",
    "  'customer_rating_clean','customer_city_clean'\n",
    "]\n",
    "print(\"\\nMissing counts for key cleaned cols:\")\n",
    "print(df[cols_check].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0498f018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_date_clean</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>original_price_clean</th>\n",
       "      <th>is_prime_member</th>\n",
       "      <th>is_prime_member_clean</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>customer_rating_clean</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_city_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>123614.29</td>\n",
       "      <td>123614.29</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>allahabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>97644.25</td>\n",
       "      <td>97644.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>21,947.26</td>\n",
       "      <td>21947.26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Ludhiana</td>\n",
       "      <td>ludhiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>131194.65</td>\n",
       "      <td>131194.65</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>86987.64</td>\n",
       "      <td>86987.64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>lucknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>32169.01</td>\n",
       "      <td>32169.01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>jaipur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>40264.16</td>\n",
       "      <td>40264.16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>bhubaneswar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>88664.85</td>\n",
       "      <td>88664.85</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>73967.02</td>\n",
       "      <td>73967.02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>72564.1</td>\n",
       "      <td>72564.10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>209875.55</td>\n",
       "      <td>209875.55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4/5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45363.47</td>\n",
       "      <td>45363.47</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_date order_date_clean original_price_inr  original_price_clean  \\\n",
       "0   2015-01-25       2015-01-25          123614.29             123614.29   \n",
       "1   2015-01-05       2015-01-05           54731.86              54731.86   \n",
       "2   2015-01-24       2015-01-24           97644.25              97644.25   \n",
       "3   2015-01-28       2015-01-28          21,947.26              21947.26   \n",
       "4   2015-01-31       2015-01-31           54731.86              54731.86   \n",
       "5   2015-01-04       2015-01-04          131194.65             131194.65   \n",
       "6   2015-01-27       2015-01-27           86987.64              86987.64   \n",
       "7   2015-01-08       2015-01-08           32169.01              32169.01   \n",
       "8   2015-01-18       2015-01-18           40264.16              40264.16   \n",
       "9   2015-01-03       2015-01-03           54731.86              54731.86   \n",
       "10  2015-01-25       2015-01-25           88664.85              88664.85   \n",
       "11  2015-01-15       2015-01-15           73967.02              73967.02   \n",
       "12  2015-01-26       2015-01-26            72564.1              72564.10   \n",
       "13  2015-01-11       2015-01-11          209875.55             209875.55   \n",
       "14  2015-01-08       2015-01-08           45363.47              45363.47   \n",
       "\n",
       "   is_prime_member  is_prime_member_clean customer_rating  \\\n",
       "0               No                  False             5.0   \n",
       "1            False                  False             4.5   \n",
       "2            False                  False             NaN   \n",
       "3            False                  False             3.0   \n",
       "4            False                  False             4.0   \n",
       "5            False                  False             4.5   \n",
       "6            False                  False             3.5   \n",
       "7            False                  False             4.0   \n",
       "8            False                  False             5.0   \n",
       "9            False                  False             4.5   \n",
       "10              No                  False             5.0   \n",
       "11           False                  False             4.5   \n",
       "12           False                  False             NaN   \n",
       "13           False                  False             4/5   \n",
       "14           False                  False             4.5   \n",
       "\n",
       "    customer_rating_clean customer_city customer_city_clean  \n",
       "0                     5.0        Mumbai              mumbai  \n",
       "1                     4.5     Allahabad           allahabad  \n",
       "2                     NaN        Mumbai              mumbai  \n",
       "3                     3.0       Kolkata             kolkata  \n",
       "4                     4.0      Ludhiana            ludhiana  \n",
       "5                     4.5         Delhi               delhi  \n",
       "6                     3.5       Lucknow             lucknow  \n",
       "7                     4.0        Jaipur              jaipur  \n",
       "8                     5.0         Delhi               delhi  \n",
       "9                     4.5   Bhubaneswar         bhubaneswar  \n",
       "10                    5.0     Ahmedabad           ahmedabad  \n",
       "11                    4.5     Bangalore           bangalore  \n",
       "12                    NaN         Delhi               delhi  \n",
       "13                    4.0        Mumbai              mumbai  \n",
       "14                    4.5     Bangalore           bangalore  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A2 - sample rows to visually inspect\n",
    "df[['order_date','order_date_clean','original_price_inr','original_price_clean',\n",
    "    'is_prime_member','is_prime_member_clean','customer_rating','customer_rating_clean',\n",
    "    'customer_city','customer_city_clean']].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88761c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min/max order_date_clean: 2015-01-01 00:00:00 2015-12-31 00:00:00\n",
      "year value counts (top):\n",
      "order_date_clean\n",
      "2015    33165\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A3 - date range\n",
    "print(\"min/max order_date_clean:\", df['order_date_clean'].min(), df['order_date_clean'].max())\n",
    "print(\"year value counts (top):\")\n",
    "print(df['order_date_clean'].dt.year.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e56941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned sample to: c:\\Users\\DELL\\Desktop\\amazon_project\\data_cleaned\\amazon_india_2015_clean_sample.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "out_dir = Path.cwd().parent / \"data_cleaned\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_path = out_dir / \"amazon_india_2015_clean_sample.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved cleaned sample to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c0e6cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_clean</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>subcategory_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>laptops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Tablets</td>\n",
       "      <td>tablets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>smartphones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Smart Watch</td>\n",
       "      <td>smart watch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category category_clean  subcategory subcategory_clean\n",
       "0   Electronics    electronics  Smartphones       smartphones\n",
       "1   Electronics    electronics  Smartphones       smartphones\n",
       "2   Electronics    electronics  Smartphones       smartphones\n",
       "3   Electronics    electronics  Smartphones       smartphones\n",
       "4   Electronics    electronics  Smartphones       smartphones\n",
       "5   Electronics    electronics      Laptops           laptops\n",
       "6   Electronics    electronics  Smartphones       smartphones\n",
       "7   Electronics    electronics  Smartphones       smartphones\n",
       "8   Electronics    electronics  Smartphones       smartphones\n",
       "9   Electronics    electronics  Smartphones       smartphones\n",
       "10  ELECTRONICS    electronics  Smartphones       smartphones\n",
       "11  Electronics    electronics      Tablets           tablets\n",
       "12  Electronics    electronics  Smartphones       smartphones\n",
       "13  Electronics    electronics  Smartphones       smartphones\n",
       "14  Electronics    electronics  Smart Watch       smart watch"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Clean category and subcategory\n",
    "\n",
    "def clean_text(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).lower().strip()\n",
    "    s = s.replace(\"&\", \"and\")          # unify electronics & accessories → electronics and accessories\n",
    "    s = \" \".join(s.split())            # remove double spaces\n",
    "    return s\n",
    "\n",
    "df['category_clean'] = df['category'].apply(clean_text)\n",
    "df['subcategory_clean'] = df['subcategory'].apply(clean_text)\n",
    "\n",
    "# Mapping known variants\n",
    "category_map = {\n",
    "    \"electronics and accessories\": \"electronics\",\n",
    "    \"electronic\": \"electronics\",\n",
    "    \"electronics accessories\": \"electronics\",\n",
    "    \"mobile phones\": \"mobiles\",\n",
    "    \"mobile and accessories\": \"mobiles\",\n",
    "    \"fashion men\": \"fashion\",\n",
    "    \"fashion women\": \"fashion\",\n",
    "}\n",
    "\n",
    "def map_category(s):\n",
    "    if s in category_map:\n",
    "        return category_map[s]\n",
    "    # try partial match\n",
    "    for k, v in category_map.items():\n",
    "        if k in s:\n",
    "            return v\n",
    "    return s\n",
    "\n",
    "df['category_clean'] = df['category_clean'].apply(map_category)\n",
    "\n",
    "df[['category', 'category_clean', 'subcategory', 'subcategory_clean']].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c99d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delivery_days</th>\n",
       "      <th>delivery_days_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delivery_days  delivery_days_clean\n",
       "0              6                  6.0\n",
       "1              4                  4.0\n",
       "2              4                  4.0\n",
       "3              4                  4.0\n",
       "4              3                  3.0\n",
       "5              3                  3.0\n",
       "6              4                  4.0\n",
       "7              3                  3.0\n",
       "8              3                  3.0\n",
       "9              5                  5.0\n",
       "10             4                  4.0\n",
       "11             3                  3.0\n",
       "12             4                  4.0\n",
       "13             4                  4.0\n",
       "14             4                  4.0\n",
       "15             4                  4.0\n",
       "16             5                  5.0\n",
       "17             7                  7.0\n",
       "18             3                  3.0\n",
       "19             5                  5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: Clean delivery_days → numeric\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_delivery_days(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    \n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # same day handling\n",
    "    if s in [\"same day\", \"sameday\", \"0\", \"0 day\", \"0 days\"]:\n",
    "        return 0.0\n",
    "    \n",
    "    # range like \"1-3 days\" or \"1 to 4 days\"\n",
    "    m_range = re.search(r'(\\d{1,2})\\s*[-to]+\\s*(\\d{1,2})', s)\n",
    "    if m_range:\n",
    "        a = int(m_range.group(1))\n",
    "        b = int(m_range.group(2))\n",
    "        return (a + b) / 2   # midpoint\n",
    "    \n",
    "    # direct number inside the string\n",
    "    m_num = re.search(r'(\\d{1,2})', s)\n",
    "    if m_num:\n",
    "        return float(m_num.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "df['delivery_days_clean'] = df['delivery_days'].apply(clean_delivery_days)\n",
    "\n",
    "df[['delivery_days', 'delivery_days_clean']].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b42d7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payment_method_clean\n",
       "COD           24962\n",
       "Card           6607\n",
       "NetBanking     1596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3: Clean payment_method → UPI / Card / COD / NetBanking\n",
    "\n",
    "def clean_payment_method(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).lower().replace(\" \", \"\").replace(\"-\", \"\")\n",
    "    \n",
    "    # UPI group\n",
    "    if any(k in s for k in ['upi', 'gpay', 'googlepay', 'phonepe', 'paytm']):\n",
    "        return 'UPI'\n",
    "    \n",
    "    # Card group\n",
    "    if any(k in s for k in ['credit', 'debit', 'card', 'cc']):\n",
    "        return 'Card'\n",
    "    \n",
    "    # Cash on Delivery\n",
    "    if 'cod' in s or 'cashondelivery' in s or 'cash' in s:\n",
    "        return 'COD'\n",
    "    \n",
    "    # Netbanking\n",
    "    if 'netbank' in s or 'netbanking' in s:\n",
    "        return 'NetBanking'\n",
    "    \n",
    "    return s.capitalize()  # fallback clean format\n",
    "\n",
    "# apply\n",
    "df['payment_method_clean'] = df['payment_method'].apply(clean_payment_method)\n",
    "\n",
    "# show top results\n",
    "df['payment_method_clean'].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7dadfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 33165\n",
      "\n",
      "[Exact Duplicate transaction_id]\n",
      "Rows duplicated: 0\n",
      "Distinct transaction_id duplicated: 0\n",
      "\n",
      "[Potential Duplicate Rows]\n",
      "Rows duplicated in candidate set: 330\n",
      "Distinct duplicate groups: 165\n",
      "\n",
      "Sample potential-duplicate rows (first 5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>original_price_clean</th>\n",
       "      <th>is_prime_member_clean</th>\n",
       "      <th>is_festival_sale_clean</th>\n",
       "      <th>is_prime_eligible_clean</th>\n",
       "      <th>customer_rating_clean</th>\n",
       "      <th>customer_city_clean</th>\n",
       "      <th>category_clean</th>\n",
       "      <th>subcategory_clean</th>\n",
       "      <th>delivery_days_clean</th>\n",
       "      <th>payment_method_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>TXN_2015_00001852</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>CUST_2015_00000037</td>\n",
       "      <td>PROD_000053</td>\n",
       "      <td>OnePlus OnePlus 2 32GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>delhi</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33077</th>\n",
       "      <td>TXN_2015_00001852_DUP</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>CUST_2015_00000037</td>\n",
       "      <td>PROD_000053</td>\n",
       "      <td>OnePlus OnePlus 2 32GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>delhi</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11861</th>\n",
       "      <td>TXN_2015_00011862</td>\n",
       "      <td>23-05-2015</td>\n",
       "      <td>CUST_2015_00000173</td>\n",
       "      <td>PROD_001820</td>\n",
       "      <td>OnePlus Neckband Premium</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Audio</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>19375.09</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>19375.09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>delhi</td>\n",
       "      <td>electronics</td>\n",
       "      <td>audio</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33063</th>\n",
       "      <td>TXN_2015_00011862_DUP</td>\n",
       "      <td>23-05-2015</td>\n",
       "      <td>CUST_2015_00000173</td>\n",
       "      <td>PROD_001820</td>\n",
       "      <td>OnePlus Neckband Premium</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Audio</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>19375.09</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>19375.09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>delhi</td>\n",
       "      <td>electronics</td>\n",
       "      <td>audio</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18161</th>\n",
       "      <td>TXN_2015_00018162</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>CUST_2015_00000265</td>\n",
       "      <td>PROD_000071</td>\n",
       "      <td>Xiaomi Redmi 2 32GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>44203.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44203.12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.5</td>\n",
       "      <td>kolkata</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              transaction_id  order_date         customer_id   product_id  \\\n",
       "1851       TXN_2015_00001852  2015-01-23  CUST_2015_00000037  PROD_000053   \n",
       "33077  TXN_2015_00001852_DUP  2015-01-23  CUST_2015_00000037  PROD_000053   \n",
       "11861      TXN_2015_00011862  23-05-2015  CUST_2015_00000173  PROD_001820   \n",
       "33063  TXN_2015_00011862_DUP  23-05-2015  CUST_2015_00000173  PROD_001820   \n",
       "18161      TXN_2015_00018162  2015-08-25  CUST_2015_00000265  PROD_000071   \n",
       "\n",
       "                       product_name     category  subcategory    brand  \\\n",
       "1851   OnePlus OnePlus 2 32GB Black  Electronics  Smartphones  OnePlus   \n",
       "33077  OnePlus OnePlus 2 32GB Black  Electronics  Smartphones  OnePlus   \n",
       "11861      OnePlus Neckband Premium  Electronics        Audio  OnePlus   \n",
       "33063      OnePlus Neckband Premium  Electronics        Audio  OnePlus   \n",
       "18161     Xiaomi Redmi 2 32GB Black  Electronics  Smartphones   Xiaomi   \n",
       "\n",
       "      original_price_inr  discount_percent  ...  original_price_clean  \\\n",
       "1851           102649.14              19.3  ...             102649.14   \n",
       "33077          102649.14              19.3  ...             102649.14   \n",
       "11861           19375.09              13.4  ...              19375.09   \n",
       "33063           19375.09              13.4  ...              19375.09   \n",
       "18161           44203.12               0.0  ...              44203.12   \n",
       "\n",
       "       is_prime_member_clean  is_festival_sale_clean  is_prime_eligible_clean  \\\n",
       "1851                   False                    True                     True   \n",
       "33077                  False                    True                     True   \n",
       "11861                  False                   False                    False   \n",
       "33063                  False                   False                    False   \n",
       "18161                  False                   False                     True   \n",
       "\n",
       "       customer_rating_clean customer_city_clean category_clean  \\\n",
       "1851                     5.0               delhi    electronics   \n",
       "33077                    5.0               delhi    electronics   \n",
       "11861                    3.5               delhi    electronics   \n",
       "33063                    3.5               delhi    electronics   \n",
       "18161                    4.5             kolkata    electronics   \n",
       "\n",
       "      subcategory_clean delivery_days_clean payment_method_clean  \n",
       "1851        smartphones                 5.0                  COD  \n",
       "33077       smartphones                 5.0                  COD  \n",
       "11861             audio                 4.0                  COD  \n",
       "33063             audio                 4.0                  COD  \n",
       "18161       smartphones                 4.0                 Card  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suggested strategy:\n",
      "- Keep one row per transaction_id if exact duplicates exist.\n",
      "- For customer/product/date/amount duplicates, inspect quantity:\n",
      "  If quantity differs -> legitimate multi-item order.\n",
      "  If rows identical -> treat as true duplicates.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Duplicate detection (clean version)\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Exact duplicate transaction_id\n",
    "# -------------------------------\n",
    "\n",
    "dup_tid = df[df.duplicated(subset=['transaction_id'], keep=False)].sort_values('transaction_id')\n",
    "\n",
    "num_dup_tid_rows = len(dup_tid)\n",
    "num_dup_tid_ids = dup_tid['transaction_id'].nunique()\n",
    "\n",
    "print(\"\\n[Exact Duplicate transaction_id]\")\n",
    "print(\"Rows duplicated:\", num_dup_tid_rows)\n",
    "print(\"Distinct transaction_id duplicated:\", num_dup_tid_ids)\n",
    "\n",
    "if num_dup_tid_rows > 0:\n",
    "    print(\"\\nSample exact-duplicate rows (first 5):\")\n",
    "    display(dup_tid.head(5))\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Potential duplicates\n",
    "# (same customer, product, date, amount)\n",
    "# -------------------------------\n",
    "\n",
    "dup_cand = df[df.duplicated(\n",
    "    subset=['customer_id','product_id','order_date_clean','final_amount_inr'],\n",
    "    keep=False\n",
    ")].sort_values(['customer_id','product_id','order_date_clean','final_amount_inr'])\n",
    "\n",
    "num_dup_cand_rows = len(dup_cand)\n",
    "num_dup_cand_groups = dup_cand[['customer_id','product_id','order_date_clean','final_amount_inr']].drop_duplicates().shape[0]\n",
    "\n",
    "print(\"\\n[Potential Duplicate Rows]\")\n",
    "print(\"Rows duplicated in candidate set:\", num_dup_cand_rows)\n",
    "print(\"Distinct duplicate groups:\", num_dup_cand_groups)\n",
    "\n",
    "if num_dup_cand_rows > 0:\n",
    "    print(\"\\nSample potential-duplicate rows (first 5):\")\n",
    "    display(dup_cand.head(5))\n",
    "\n",
    "print(\"\\nSuggested strategy:\")\n",
    "print(\"- Keep one row per transaction_id if exact duplicates exist.\")\n",
    "print(\"- For customer/product/date/amount duplicates, inspect quantity:\")\n",
    "print(\"  If quantity differs -> legitimate multi-item order.\")\n",
    "print(\"  If rows identical -> treat as true duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "986789af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate groups found (count): 165\n",
      "Top 5 duplicate groups (customer_id, product_id, date, amount, group_size):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_date_clean</th>\n",
       "      <th>final_amount_inr</th>\n",
       "      <th>group_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>CUST_2015_00000037</td>\n",
       "      <td>PROD_000053</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>82840.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>CUST_2015_00000173</td>\n",
       "      <td>PROD_001820</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>16779.59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>CUST_2015_00000265</td>\n",
       "      <td>PROD_000071</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>132609.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>CUST_2015_00000326</td>\n",
       "      <td>PROD_000036</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>88872.68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>CUST_2015_00000433</td>\n",
       "      <td>PROD_000071</td>\n",
       "      <td>2015-09-08</td>\n",
       "      <td>40751.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_id   product_id order_date_clean  final_amount_inr  \\\n",
       "101   CUST_2015_00000037  PROD_000053       2015-01-23          82840.60   \n",
       "418   CUST_2015_00000173  PROD_001820       2015-05-23          16779.59   \n",
       "666   CUST_2015_00000265  PROD_000071       2015-08-25         132609.36   \n",
       "865   CUST_2015_00000326  PROD_000036       2015-07-27          88872.68   \n",
       "1149  CUST_2015_00000433  PROD_000071       2015-09-08          40751.36   \n",
       "\n",
       "      group_size  \n",
       "101            2  \n",
       "418            2  \n",
       "666            2  \n",
       "865            2  \n",
       "1149           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample rows for the top duplicate group: ('CUST_2015_00000037', 'PROD_000053', Timestamp('2015-01-23 00:00:00'), np.float64(82840.6))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>original_price_clean</th>\n",
       "      <th>is_prime_member_clean</th>\n",
       "      <th>is_festival_sale_clean</th>\n",
       "      <th>is_prime_eligible_clean</th>\n",
       "      <th>customer_rating_clean</th>\n",
       "      <th>customer_city_clean</th>\n",
       "      <th>category_clean</th>\n",
       "      <th>subcategory_clean</th>\n",
       "      <th>delivery_days_clean</th>\n",
       "      <th>payment_method_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>TXN_2015_00001852</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>CUST_2015_00000037</td>\n",
       "      <td>PROD_000053</td>\n",
       "      <td>OnePlus OnePlus 2 32GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>delhi</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33077</th>\n",
       "      <td>TXN_2015_00001852_DUP</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>CUST_2015_00000037</td>\n",
       "      <td>PROD_000053</td>\n",
       "      <td>OnePlus OnePlus 2 32GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>102649.14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>delhi</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              transaction_id  order_date         customer_id   product_id  \\\n",
       "1851       TXN_2015_00001852  2015-01-23  CUST_2015_00000037  PROD_000053   \n",
       "33077  TXN_2015_00001852_DUP  2015-01-23  CUST_2015_00000037  PROD_000053   \n",
       "\n",
       "                       product_name     category  subcategory    brand  \\\n",
       "1851   OnePlus OnePlus 2 32GB Black  Electronics  Smartphones  OnePlus   \n",
       "33077  OnePlus OnePlus 2 32GB Black  Electronics  Smartphones  OnePlus   \n",
       "\n",
       "      original_price_inr  discount_percent  ...  original_price_clean  \\\n",
       "1851           102649.14              19.3  ...             102649.14   \n",
       "33077          102649.14              19.3  ...             102649.14   \n",
       "\n",
       "       is_prime_member_clean  is_festival_sale_clean  is_prime_eligible_clean  \\\n",
       "1851                   False                    True                     True   \n",
       "33077                  False                    True                     True   \n",
       "\n",
       "       customer_rating_clean customer_city_clean category_clean  \\\n",
       "1851                     5.0               delhi    electronics   \n",
       "33077                    5.0               delhi    electronics   \n",
       "\n",
       "      subcategory_clean delivery_days_clean payment_method_clean  \n",
       "1851        smartphones                 5.0                  COD  \n",
       "33077       smartphones                 5.0                  COD  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows in duplicate groups (total): 330\n",
      "Rows to KEEP (one per group): 165\n",
      "Rows that will be DROPPED: 165\n",
      "\n",
      "Shape before dedup: (33165, 46)\n",
      "Shape after dedup (if applied): (33000, 46)\n",
      "\n",
      "Summary flags counts:\n",
      "in_dup_group    330\n",
      "dup_keep        165\n",
      "dup_to_drop     165\n",
      "dtype: int64\n",
      "\n",
      "Example rows that would be dropped (first 5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>is_prime_eligible_clean</th>\n",
       "      <th>customer_rating_clean</th>\n",
       "      <th>customer_city_clean</th>\n",
       "      <th>category_clean</th>\n",
       "      <th>subcategory_clean</th>\n",
       "      <th>delivery_days_clean</th>\n",
       "      <th>payment_method_clean</th>\n",
       "      <th>in_dup_group</th>\n",
       "      <th>dup_keep</th>\n",
       "      <th>dup_to_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>TXN_2015_00016501_DUP</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>CUST_2015_00010086</td>\n",
       "      <td>PROD_001781</td>\n",
       "      <td>Boat Earbuds Premium</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Audio</td>\n",
       "      <td>Boat</td>\n",
       "      <td>17174.29</td>\n",
       "      <td>28.81</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pune</td>\n",
       "      <td>electronics</td>\n",
       "      <td>audio</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33001</th>\n",
       "      <td>TXN_2015_00014828_DUP</td>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>CUST_2015_00003428</td>\n",
       "      <td>PROD_001719</td>\n",
       "      <td>Xiaomi iPad 4GB RAM Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Tablets</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>29675.17</td>\n",
       "      <td>50.41</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.5</td>\n",
       "      <td>delhi ncr</td>\n",
       "      <td>electronics</td>\n",
       "      <td>tablets</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Card</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33002</th>\n",
       "      <td>TXN_2015_00020641_DUP</td>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>CUST_2015_00011426</td>\n",
       "      <td>PROD_000033</td>\n",
       "      <td>Samsung Galaxy S6 Edge 32GB White</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>167952.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>chennai</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>TXN_2015_00007274_DUP</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>CUST_2015_00004028</td>\n",
       "      <td>PROD_000066</td>\n",
       "      <td>Xiaomi Mi 4i 64GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>31102.54</td>\n",
       "      <td>25.55</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>4.5</td>\n",
       "      <td>moradabad</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33004</th>\n",
       "      <td>TXN_2015_00002272_DUP</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>CUST_2015_00000924</td>\n",
       "      <td>PROD_000077</td>\n",
       "      <td>Xiaomi Redmi 2 32GB Blue</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>20175.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>vadodara</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              transaction_id  order_date         customer_id   product_id  \\\n",
       "33000  TXN_2015_00016501_DUP  2015-07-01  CUST_2015_00010086  PROD_001781   \n",
       "33001  TXN_2015_00014828_DUP  2015-07-14  CUST_2015_00003428  PROD_001719   \n",
       "33002  TXN_2015_00020641_DUP  2015-09-05  CUST_2015_00011426  PROD_000033   \n",
       "33003  TXN_2015_00007274_DUP  2015-04-24  CUST_2015_00004028  PROD_000066   \n",
       "33004  TXN_2015_00002272_DUP  2015-01-28  CUST_2015_00000924  PROD_000077   \n",
       "\n",
       "                            product_name     category  subcategory    brand  \\\n",
       "33000               Boat Earbuds Premium  Electronics        Audio     Boat   \n",
       "33001          Xiaomi iPad 4GB RAM Black  Electronics      Tablets   Xiaomi   \n",
       "33002  Samsung Galaxy S6 Edge 32GB White  Electronics  Smartphones  Samsung   \n",
       "33003            Xiaomi Mi 4i 64GB Black  Electronics  Smartphones   Xiaomi   \n",
       "33004           Xiaomi Redmi 2 32GB Blue  Electronics  Smartphones   Xiaomi   \n",
       "\n",
       "      original_price_inr  discount_percent  ...  is_prime_eligible_clean  \\\n",
       "33000           17174.29             28.81  ...                     True   \n",
       "33001           29675.17             50.41  ...                     True   \n",
       "33002          167952.46              0.00  ...                     True   \n",
       "33003           31102.54             25.55  ...                     True   \n",
       "33004           20175.12              0.00  ...                     True   \n",
       "\n",
       "       customer_rating_clean  customer_city_clean  category_clean  \\\n",
       "33000                    4.0                 pune     electronics   \n",
       "33001                    4.5            delhi ncr     electronics   \n",
       "33002                    4.0              chennai     electronics   \n",
       "33003                    4.5            moradabad     electronics   \n",
       "33004                    5.0             vadodara     electronics   \n",
       "\n",
       "       subcategory_clean delivery_days_clean payment_method_clean  \\\n",
       "33000              audio                 3.0                  COD   \n",
       "33001            tablets                 5.0                 Card   \n",
       "33002        smartphones                 3.0                  COD   \n",
       "33003        smartphones                 3.0                  COD   \n",
       "33004        smartphones                 4.0                  COD   \n",
       "\n",
       "      in_dup_group dup_keep dup_to_drop  \n",
       "33000         True    False        True  \n",
       "33001         True    False        True  \n",
       "33002         True    False        True  \n",
       "33003         True    False        True  \n",
       "33004         True    False        True  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAFE DEDUPLICATION for potential duplicate groups\n",
    "from IPython.display import display\n",
    "\n",
    "keys = ['customer_id','product_id','order_date_clean','final_amount_inr']\n",
    "\n",
    "# 1) Show top duplicate groups (for inspection)\n",
    "dup_groups = df.groupby(keys).size().reset_index(name='group_size')\n",
    "dup_groups = dup_groups[dup_groups['group_size'] > 1].sort_values('group_size', ascending=False)\n",
    "print(\"Duplicate groups found (count):\", len(dup_groups))\n",
    "print(\"Top 5 duplicate groups (customer_id, product_id, date, amount, group_size):\")\n",
    "display(dup_groups.head(5))\n",
    "\n",
    "# show sample rows from one of the top duplicate groups to inspect\n",
    "if len(dup_groups):\n",
    "    sample_key = tuple(dup_groups.head(1)[keys].iloc[0])\n",
    "    print(\"\\nSample rows for the top duplicate group:\", sample_key)\n",
    "    sample_rows = df[(df['customer_id']==sample_key[0]) &\n",
    "                     (df['product_id']==sample_key[1]) &\n",
    "                     (df['order_date_clean']==sample_key[2]) &\n",
    "                     (df['final_amount_inr']==sample_key[3])]\n",
    "    display(sample_rows)\n",
    "\n",
    "# 2) Conservative dedup strategy:\n",
    "# Keep one row per duplicate group: the row with highest 'quantity' (ties -> first)\n",
    "dup_keys = dup_groups[keys].itertuples(index=False, name=None)\n",
    "\n",
    "idxs_to_keep = []\n",
    "idxs_all_in_dup_groups = []\n",
    "\n",
    "for key in dup_keys:\n",
    "    cust, prod, date, amt = key\n",
    "    mask = (df['customer_id']==cust) & (df['product_id']==prod) & (df['order_date_clean']==date) & (df['final_amount_inr']==amt)\n",
    "    group_idx = df[mask].index.tolist()\n",
    "    idxs_all_in_dup_groups.extend(group_idx)\n",
    "    # choose index with max quantity\n",
    "    idx_max_qty = df.loc[group_idx, 'quantity'].idxmax()\n",
    "    idxs_to_keep.append(idx_max_qty)\n",
    "\n",
    "idxs_all_in_dup_groups = pd.Index(idxs_all_in_dup_groups)\n",
    "idxs_to_keep = pd.Index(idxs_to_keep)\n",
    "\n",
    "# compute rows that would be dropped (members of duplicate groups but not the chosen keepers)\n",
    "rows_to_drop = idxs_all_in_dup_groups.difference(idxs_to_keep)\n",
    "print(\"\\nRows in duplicate groups (total):\", len(idxs_all_in_dup_groups))\n",
    "print(\"Rows to KEEP (one per group):\", len(idxs_to_keep))\n",
    "print(\"Rows that will be DROPPED:\", len(rows_to_drop))\n",
    "\n",
    "# 3) Create a copy and drop them (safe: we'll not overwrite df until we confirm)\n",
    "df_dedup = df.drop(index=rows_to_drop).copy()\n",
    "print(\"\\nShape before dedup:\", df.shape)\n",
    "print(\"Shape after dedup (if applied):\", df_dedup.shape)\n",
    "\n",
    "# 4) Add a flag column to original df for traceability, then replace df if you want\n",
    "df['in_dup_group'] = df.index.isin(idxs_all_in_dup_groups)\n",
    "df['dup_keep'] = df.index.isin(idxs_to_keep)\n",
    "df['dup_to_drop'] = df.index.isin(rows_to_drop)\n",
    "\n",
    "print(\"\\nSummary flags counts:\")\n",
    "print(df[['in_dup_group','dup_keep','dup_to_drop']].sum())\n",
    "\n",
    "# show a few rows marked for drop\n",
    "if len(rows_to_drop):\n",
    "    print(\"\\nExample rows that would be dropped (first 5):\")\n",
    "    display(df.loc[rows_to_drop].head(5))\n",
    "\n",
    "# NOTE: we have not overwritten `df`. If you are happy and want to make the change permanent:\n",
    "# run: df = df_dedup.copy()\n",
    "#\n",
    "# If you want to save now:\n",
    "# df_dedup.to_csv(out_dir / \"amazon_india_2015_clean_part3_dedup.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cf941e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape after applying dedup: (33000, 46)\n"
     ]
    }
   ],
   "source": [
    "# APPLY DEDUPLICATION\n",
    "df = df_dedup.copy()\n",
    "\n",
    "print(\"New shape after applying dedup:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e87f754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final deduped file to: c:\\Users\\DELL\\Desktop\\amazon_project\\data_cleaned\\amazon_india_2015_clean_dedup.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(out_dir / \"amazon_india_2015_clean_dedup.csv\", index=False)\n",
    "print(\"Saved final deduped file to:\", out_dir / \"amazon_india_2015_clean_dedup.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f1b1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 33000\n",
      "Price missing (clean): 985\n",
      "Suspect price rows (>30x product median or >1,000,000): 98\n",
      "\n",
      "price ratio summary (non-null):\n",
      "count    32015.000000\n",
      "mean         1.276214\n",
      "std          5.083824\n",
      "min         -1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max        100.000000\n",
      "\n",
      "Top 20 suspect rows (highest ratio):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>original_price_clean</th>\n",
       "      <th>prod_median_price</th>\n",
       "      <th>price_gt_median_ratio</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22573</th>\n",
       "      <td>TXN_2015_00022574</td>\n",
       "      <td>PROD_001733</td>\n",
       "      <td>OnePlus Galaxy Tab 4GB RAM Silver</td>\n",
       "      <td>4623409.0</td>\n",
       "      <td>46234.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209</th>\n",
       "      <td>TXN_2015_00013210</td>\n",
       "      <td>PROD_000085</td>\n",
       "      <td>Motorola Moto G (3rd Gen) 16GB Black</td>\n",
       "      <td>2194726.0</td>\n",
       "      <td>21947.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>TXN_2015_00026706</td>\n",
       "      <td>PROD_000036</td>\n",
       "      <td>Samsung Galaxy S6 Edge 16GB Gold</td>\n",
       "      <td>8887268.0</td>\n",
       "      <td>88872.68</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>TXN_2015_00001320</td>\n",
       "      <td>PROD_000073</td>\n",
       "      <td>Xiaomi Redmi 2 16GB White</td>\n",
       "      <td>4376740.0</td>\n",
       "      <td>43767.40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>TXN_2015_00001834</td>\n",
       "      <td>PROD_001713</td>\n",
       "      <td>Lenovo Pad 8GB RAM Silver</td>\n",
       "      <td>6744491.0</td>\n",
       "      <td>67444.91</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>TXN_2015_00002321</td>\n",
       "      <td>PROD_000071</td>\n",
       "      <td>Xiaomi Redmi 2 32GB Black</td>\n",
       "      <td>4420312.0</td>\n",
       "      <td>44203.12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>TXN_2015_00002466</td>\n",
       "      <td>PROD_000035</td>\n",
       "      <td>Samsung Galaxy S6 Edge 32GB Blue</td>\n",
       "      <td>11728933.0</td>\n",
       "      <td>117289.33</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>TXN_2015_00001479</td>\n",
       "      <td>PROD_001983</td>\n",
       "      <td>Samsung OLED TV</td>\n",
       "      <td>3888419.0</td>\n",
       "      <td>38884.19</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>TXN_2015_00002985</td>\n",
       "      <td>PROD_000092</td>\n",
       "      <td>Motorola Moto G (3rd Gen) 16GB Gold</td>\n",
       "      <td>1786925.0</td>\n",
       "      <td>17869.25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>TXN_2015_00003682</td>\n",
       "      <td>PROD_000070</td>\n",
       "      <td>Xiaomi Redmi 2 16GB Black</td>\n",
       "      <td>2953470.0</td>\n",
       "      <td>29534.70</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>TXN_2015_00003904</td>\n",
       "      <td>PROD_001820</td>\n",
       "      <td>OnePlus Neckband Premium</td>\n",
       "      <td>1937509.0</td>\n",
       "      <td>19375.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>TXN_2015_00004050</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>5473186.0</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>TXN_2015_00004295</td>\n",
       "      <td>PROD_000052</td>\n",
       "      <td>OnePlus OnePlus 2 16GB Black</td>\n",
       "      <td>7256410.0</td>\n",
       "      <td>72564.10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>TXN_2015_00004315</td>\n",
       "      <td>PROD_000039</td>\n",
       "      <td>Samsung Galaxy Note 5 64GB Black</td>\n",
       "      <td>9764425.0</td>\n",
       "      <td>97644.25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>TXN_2015_00004336</td>\n",
       "      <td>PROD_000005</td>\n",
       "      <td>Apple iPhone 6 32GB White</td>\n",
       "      <td>11480624.0</td>\n",
       "      <td>114806.24</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>TXN_2015_00002517</td>\n",
       "      <td>PROD_001737</td>\n",
       "      <td>OnePlus Pad 4GB RAM Silver</td>\n",
       "      <td>3901009.0</td>\n",
       "      <td>39010.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>TXN_2015_00004531</td>\n",
       "      <td>PROD_000076</td>\n",
       "      <td>Xiaomi Redmi 2 16GB Blue</td>\n",
       "      <td>3635060.0</td>\n",
       "      <td>36350.60</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>TXN_2015_00004840</td>\n",
       "      <td>PROD_000061</td>\n",
       "      <td>OnePlus OnePlus X 32GB White</td>\n",
       "      <td>8295319.0</td>\n",
       "      <td>82953.19</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>TXN_2015_00005438</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>5473186.0</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>TXN_2015_00006941</td>\n",
       "      <td>PROD_000048</td>\n",
       "      <td>Samsung Galaxy J7 16GB White</td>\n",
       "      <td>3216901.0</td>\n",
       "      <td>32169.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_id   product_id                          product_name  \\\n",
       "22573  TXN_2015_00022574  PROD_001733     OnePlus Galaxy Tab 4GB RAM Silver   \n",
       "13209  TXN_2015_00013210  PROD_000085  Motorola Moto G (3rd Gen) 16GB Black   \n",
       "26705  TXN_2015_00026706  PROD_000036      Samsung Galaxy S6 Edge 16GB Gold   \n",
       "1319   TXN_2015_00001320  PROD_000073             Xiaomi Redmi 2 16GB White   \n",
       "1833   TXN_2015_00001834  PROD_001713             Lenovo Pad 8GB RAM Silver   \n",
       "2320   TXN_2015_00002321  PROD_000071             Xiaomi Redmi 2 32GB Black   \n",
       "2465   TXN_2015_00002466  PROD_000035      Samsung Galaxy S6 Edge 32GB Blue   \n",
       "1478   TXN_2015_00001479  PROD_001983                       Samsung OLED TV   \n",
       "2984   TXN_2015_00002985  PROD_000092   Motorola Moto G (3rd Gen) 16GB Gold   \n",
       "3681   TXN_2015_00003682  PROD_000070             Xiaomi Redmi 2 16GB Black   \n",
       "3903   TXN_2015_00003904  PROD_001820              OnePlus Neckband Premium   \n",
       "4049   TXN_2015_00004050  PROD_000055          OnePlus OnePlus 2 16GB White   \n",
       "4294   TXN_2015_00004295  PROD_000052          OnePlus OnePlus 2 16GB Black   \n",
       "4314   TXN_2015_00004315  PROD_000039      Samsung Galaxy Note 5 64GB Black   \n",
       "4335   TXN_2015_00004336  PROD_000005             Apple iPhone 6 32GB White   \n",
       "2516   TXN_2015_00002517  PROD_001737            OnePlus Pad 4GB RAM Silver   \n",
       "4530   TXN_2015_00004531  PROD_000076              Xiaomi Redmi 2 16GB Blue   \n",
       "4839   TXN_2015_00004840  PROD_000061          OnePlus OnePlus X 32GB White   \n",
       "5437   TXN_2015_00005438  PROD_000055          OnePlus OnePlus 2 16GB White   \n",
       "6940   TXN_2015_00006941  PROD_000048          Samsung Galaxy J7 16GB White   \n",
       "\n",
       "       original_price_clean  prod_median_price  price_gt_median_ratio  \\\n",
       "22573             4623409.0           46234.09                  100.0   \n",
       "13209             2194726.0           21947.26                  100.0   \n",
       "26705             8887268.0           88872.68                  100.0   \n",
       "1319              4376740.0           43767.40                  100.0   \n",
       "1833              6744491.0           67444.91                  100.0   \n",
       "2320              4420312.0           44203.12                  100.0   \n",
       "2465             11728933.0          117289.33                  100.0   \n",
       "1478              3888419.0           38884.19                  100.0   \n",
       "2984              1786925.0           17869.25                  100.0   \n",
       "3681              2953470.0           29534.70                  100.0   \n",
       "3903              1937509.0           19375.09                  100.0   \n",
       "4049              5473186.0           54731.86                  100.0   \n",
       "4294              7256410.0           72564.10                  100.0   \n",
       "4314              9764425.0           97644.25                  100.0   \n",
       "4335             11480624.0          114806.24                  100.0   \n",
       "2516              3901009.0           39010.09                  100.0   \n",
       "4530              3635060.0           36350.60                  100.0   \n",
       "4839              8295319.0           82953.19                  100.0   \n",
       "5437              5473186.0           54731.86                  100.0   \n",
       "6940              3216901.0           32169.01                  100.0   \n",
       "\n",
       "       quantity  \n",
       "22573         1  \n",
       "13209         1  \n",
       "26705         1  \n",
       "1319          1  \n",
       "1833          2  \n",
       "2320          1  \n",
       "2465          2  \n",
       "1478          1  \n",
       "2984          1  \n",
       "3681          1  \n",
       "3903          1  \n",
       "4049          1  \n",
       "4294          1  \n",
       "4314          1  \n",
       "4335          1  \n",
       "2516          1  \n",
       "4530          1  \n",
       "4839          1  \n",
       "5437          1  \n",
       "6940          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PRICE OUTLIER DETECTION (flagging)\n",
    "import numpy as np\n",
    "\n",
    "# ensure numeric column exists\n",
    "df['original_price_clean'] = pd.to_numeric(df['original_price_clean'], errors='coerce')\n",
    "\n",
    "# product median price (skip NaNs)\n",
    "prod_median = df.groupby('product_id')['original_price_clean'].median().rename('prod_median_price')\n",
    "df = df.merge(prod_median, left_on='product_id', right_index=True, how='left')\n",
    "\n",
    "# Flags\n",
    "df['price_missing'] = df['original_price_clean'].isna()\n",
    "df['price_gt_median_ratio'] = df['original_price_clean'] / df['prod_median_price']\n",
    "df['price_gt_median_ratio'] = df['price_gt_median_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# suspicious if > 30x median OR absolute extremely high\n",
    "df['price_suspect'] = False\n",
    "mask_num = df['original_price_clean'].notna() & df['prod_median_price'].notna()\n",
    "df.loc[mask_num & (df['price_gt_median_ratio'] > 30), 'price_suspect'] = True\n",
    "df.loc[mask_num & (df['original_price_clean'] > 1_000_000), 'price_suspect'] = True\n",
    "\n",
    "# counts\n",
    "total_rows = len(df)\n",
    "num_price_missing = int(df['price_missing'].sum())\n",
    "num_suspect = int(df['price_suspect'].sum())\n",
    "\n",
    "print(\"Total rows:\", total_rows)\n",
    "print(\"Price missing (clean):\", num_price_missing)\n",
    "print(\"Suspect price rows (>30x product median or >1,000,000):\", num_suspect)\n",
    "\n",
    "# show distribution of ratio for insight (summary)\n",
    "print(\"\\nprice ratio summary (non-null):\")\n",
    "print(df.loc[mask_num, 'price_gt_median_ratio'].describe().to_string())\n",
    "\n",
    "# show top 20 most extreme suspects\n",
    "print(\"\\nTop 20 suspect rows (highest ratio):\")\n",
    "display(df.loc[df['price_suspect']].sort_values('price_gt_median_ratio', ascending=False).head(20)[\n",
    "    ['transaction_id','product_id','product_name','original_price_clean','prod_median_price','price_gt_median_ratio','quantity']\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9423d116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total suspect rows: 98\n",
      "Total corrected rows: 98\n",
      "  corrected by /100: 98\n",
      "  corrected by /10 : 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>original_price_clean</th>\n",
       "      <th>price_corrected</th>\n",
       "      <th>prod_median_price</th>\n",
       "      <th>price_gt_median_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>TXN_2015_00000446</td>\n",
       "      <td>PROD_001737</td>\n",
       "      <td>3901009.0</td>\n",
       "      <td>39010.09</td>\n",
       "      <td>39010.09</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>TXN_2015_00001195</td>\n",
       "      <td>PROD_000080</td>\n",
       "      <td>2631710.0</td>\n",
       "      <td>26317.10</td>\n",
       "      <td>26317.10</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>TXN_2015_00001320</td>\n",
       "      <td>PROD_000073</td>\n",
       "      <td>4376740.0</td>\n",
       "      <td>43767.40</td>\n",
       "      <td>43767.40</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>TXN_2015_00001479</td>\n",
       "      <td>PROD_001983</td>\n",
       "      <td>3888419.0</td>\n",
       "      <td>38884.19</td>\n",
       "      <td>38884.19</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>TXN_2015_00001834</td>\n",
       "      <td>PROD_001713</td>\n",
       "      <td>6744491.0</td>\n",
       "      <td>67444.91</td>\n",
       "      <td>67444.91</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>TXN_2015_00002321</td>\n",
       "      <td>PROD_000071</td>\n",
       "      <td>4420312.0</td>\n",
       "      <td>44203.12</td>\n",
       "      <td>44203.12</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>TXN_2015_00002466</td>\n",
       "      <td>PROD_000035</td>\n",
       "      <td>11728933.0</td>\n",
       "      <td>117289.33</td>\n",
       "      <td>117289.33</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>TXN_2015_00002517</td>\n",
       "      <td>PROD_001737</td>\n",
       "      <td>3901009.0</td>\n",
       "      <td>39010.09</td>\n",
       "      <td>39010.09</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>TXN_2015_00002985</td>\n",
       "      <td>PROD_000092</td>\n",
       "      <td>1786925.0</td>\n",
       "      <td>17869.25</td>\n",
       "      <td>17869.25</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>TXN_2015_00003682</td>\n",
       "      <td>PROD_000070</td>\n",
       "      <td>2953470.0</td>\n",
       "      <td>29534.70</td>\n",
       "      <td>29534.70</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         transaction_id   product_id  original_price_clean  price_corrected  \\\n",
       "445   TXN_2015_00000446  PROD_001737             3901009.0         39010.09   \n",
       "1194  TXN_2015_00001195  PROD_000080             2631710.0         26317.10   \n",
       "1319  TXN_2015_00001320  PROD_000073             4376740.0         43767.40   \n",
       "1478  TXN_2015_00001479  PROD_001983             3888419.0         38884.19   \n",
       "1833  TXN_2015_00001834  PROD_001713             6744491.0         67444.91   \n",
       "2320  TXN_2015_00002321  PROD_000071             4420312.0         44203.12   \n",
       "2465  TXN_2015_00002466  PROD_000035            11728933.0        117289.33   \n",
       "2516  TXN_2015_00002517  PROD_001737             3901009.0         39010.09   \n",
       "2984  TXN_2015_00002985  PROD_000092             1786925.0         17869.25   \n",
       "3681  TXN_2015_00003682  PROD_000070             2953470.0         29534.70   \n",
       "\n",
       "      prod_median_price  price_gt_median_ratio  \n",
       "445            39010.09                  100.0  \n",
       "1194           26317.10                  100.0  \n",
       "1319           43767.40                  100.0  \n",
       "1478           38884.19                  100.0  \n",
       "1833           67444.91                  100.0  \n",
       "2320           44203.12                  100.0  \n",
       "2465          117289.33                  100.0  \n",
       "2516           39010.09                  100.0  \n",
       "2984           17869.25                  100.0  \n",
       "3681           29534.70                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# APPLY CONSERVATIVE PRICE CORRECTION\n",
    "df['price_corrected'] = df['original_price_clean'].copy()\n",
    "\n",
    "changed = 0\n",
    "changed_by_100 = 0\n",
    "changed_by_10 = 0\n",
    "\n",
    "mask = df['price_suspect'] & df['original_price_clean'].notna() & df['prod_median_price'].notna()\n",
    "\n",
    "for idx in df.loc[mask].index:\n",
    "    orig = df.at[idx, 'original_price_clean']\n",
    "    med = df.at[idx, 'prod_median_price']\n",
    "    \n",
    "    candidate100 = orig / 100.0\n",
    "    candidate10 = orig / 10.0\n",
    "    \n",
    "    # prefer /100 if it becomes reasonably close to product median\n",
    "    if med > 0 and abs(candidate100 / med) <= 10:\n",
    "        df.at[idx, 'price_corrected'] = candidate100\n",
    "        changed += 1\n",
    "        changed_by_100 += 1\n",
    "        continue\n",
    "    \n",
    "    # fallback: try /10\n",
    "    if med > 0 and abs(candidate10 / med) <= 10:\n",
    "        df.at[idx, 'price_corrected'] = candidate10\n",
    "        changed += 1\n",
    "        changed_by_10 += 1\n",
    "\n",
    "print(\"Total suspect rows:\", int(mask.sum()))\n",
    "print(\"Total corrected rows:\", changed)\n",
    "print(\"  corrected by /100:\", changed_by_100)\n",
    "print(\"  corrected by /10 :\", changed_by_10)\n",
    "\n",
    "# show sample corrections\n",
    "display(df.loc[mask].head(10)[['transaction_id','product_id','original_price_clean','price_corrected','prod_median_price','price_gt_median_ratio']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d9d1592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing delivery charges: 2640\n",
      "\n",
      "Summary stats:\n",
      "count    30360.0\n",
      "mean         0.0\n",
      "std          0.0\n",
      "min          0.0\n",
      "25%          0.0\n",
      "50%          0.0\n",
      "75%          0.0\n",
      "max          0.0\n",
      "Name: delivery_charges_clean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# STEP 7A: Convert delivery_charges to numeric\n",
    "df['delivery_charges_clean'] = pd.to_numeric(df['delivery_charges'], errors='coerce')\n",
    "\n",
    "print(\"Total missing delivery charges:\", df['delivery_charges_clean'].isna().sum())\n",
    "print(\"\\nSummary stats:\")\n",
    "print(df['delivery_charges_clean'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "599a94dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing after fill: 0\n",
      "Unique values: [0.]\n"
     ]
    }
   ],
   "source": [
    "# STEP 7B: Fill missing delivery charges with 0\n",
    "df['delivery_charges_clean'] = df['delivery_charges_clean'].fillna(0)\n",
    "\n",
    "print(\"Missing after fill:\", df['delivery_charges_clean'].isna().sum())\n",
    "print(\"Unique values:\", df['delivery_charges_clean'].unique()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89662b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FULLY CLEANED file: c:\\Users\\DELL\\Desktop\\amazon_project\\data_cleaned\\amazon_india_2015_clean_final.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(out_dir / \"amazon_india_2015_clean_final.csv\", index=False)\n",
    "print(\"Saved FULLY CLEANED file:\", out_dir / \"amazon_india_2015_clean_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cc0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_orders_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Take a raw orders DataFrame and return a fully cleaned version.\n",
    "    This uses our standard cleaning steps (Q1–Q5).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Q1: standardize order_date\n",
    "    df = standardize_order_date(df, col=\"order_date\")\n",
    "\n",
    "    # Q2: clean original_price_inr\n",
    "    df = clean_price_column(df, col=\"original_price_inr\")\n",
    "\n",
    "    # Q3: clean customer_rating\n",
    "    df = clean_customer_rating(df, col=\"customer_rating\")\n",
    "\n",
    "    # Q4: standardize customer city/state\n",
    "    df = standardize_location(\n",
    "        df,\n",
    "        city_col=\"customer_city\",\n",
    "        state_col=\"customer_state\",\n",
    "    )\n",
    "\n",
    "    # Q5: normalize boolean-like columns\n",
    "    boolean_cols = [\n",
    "        \"is_prime_member\",\n",
    "        \"is_festival_sale\",\n",
    "        \"is_prime_eligible\",\n",
    "    ]\n",
    "    df = normalize_boolean_columns(df, boolean_cols)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c0cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_orders_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 👉 your 2015 cleaning steps are inside here\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bb55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # if you already imported this above, it's okay\n",
    "\n",
    "# Our folders (from the notebook, go one level up \"..\" and then into data_raw / data_cleaned)\n",
    "RAW_DIR = Path(\"../data_raw\")\n",
    "CLEAN_DIR = Path(\"../data_cleaned\")\n",
    "\n",
    "# Make sure the clean folder exists\n",
    "CLEAN_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f2be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_file(raw_path: Path):\n",
    "    \"\"\"\n",
    "    Read one raw CSV, clean it using clean_orders_df, \n",
    "    save the cleaned file, and print what happened.\n",
    "    \"\"\"\n",
    "    print(f\"\\n----- Processing: {raw_path.name} -----\")\n",
    "    try:\n",
    "        # 1) Read raw file\n",
    "        df_raw = pd.read_csv(raw_path)\n",
    "\n",
    "        # 2) Clean with your function from Step 1\n",
    "        df_clean = clean_orders_df(df_raw)\n",
    "\n",
    "        # 3) Build output file name: e.g. orders_2015.csv -> orders_2015_cleaned.csv\n",
    "        clean_name = raw_path.stem + \"_cleaned.csv\"\n",
    "        out_path = CLEAN_DIR / clean_name\n",
    "\n",
    "        # 4) Save cleaned data\n",
    "        df_clean.to_csv(out_path, index=False)\n",
    "\n",
    "        print(f\"✅ Saved cleaned file: {out_path}\")\n",
    "        return True, None   # success\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR while processing {raw_path.name}: {e}\")\n",
    "        return False, str(e)   # failed, return error message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0b5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Processing: amazon_india_2015.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2015_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2016.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2016_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2017.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2017_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2018.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2018_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2019.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2019_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2020.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2020_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2021.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2021_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2022.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2022_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2023.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2023_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2024.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2024_cleaned.csv\n",
      "\n",
      "----- Processing: amazon_india_2025.csv -----\n",
      "✅ Saved cleaned file: ..\\data_cleaned\\amazon_india_2025_cleaned.csv\n",
      "\n",
      "====== Cleaning Summary ======\n",
      "                     file  success error\n",
      "0   amazon_india_2015.csv     True  None\n",
      "1   amazon_india_2016.csv     True  None\n",
      "2   amazon_india_2017.csv     True  None\n",
      "3   amazon_india_2018.csv     True  None\n",
      "4   amazon_india_2019.csv     True  None\n",
      "5   amazon_india_2020.csv     True  None\n",
      "6   amazon_india_2021.csv     True  None\n",
      "7   amazon_india_2022.csv     True  None\n",
      "8   amazon_india_2023.csv     True  None\n",
      "9   amazon_india_2024.csv     True  None\n",
      "10  amazon_india_2025.csv     True  None\n",
      "\n",
      "📝 Log saved to: ..\\data_cleaned\\cleaning_log.csv\n"
     ]
    }
   ],
   "source": [
    "log_rows = []\n",
    "\n",
    "# Go through every .csv file inside data_raw\n",
    "for raw_path in sorted(RAW_DIR.glob(\"*.csv\")):\n",
    "    ok, err = process_one_file(raw_path)\n",
    "    log_rows.append({\n",
    "        \"file\": raw_path.name,\n",
    "        \"success\": ok,\n",
    "        \"error\": err\n",
    "    })\n",
    "\n",
    "# Turn the log into a DataFrame\n",
    "log_df = pd.DataFrame(log_rows)\n",
    "\n",
    "# Save the log into data_cleaned folder\n",
    "log_path = CLEAN_DIR / \"cleaning_log.csv\"\n",
    "log_df.to_csv(log_path, index=False)\n",
    "\n",
    "print(\"\\n====== Cleaning Summary ======\")\n",
    "print(log_df)\n",
    "print(f\"\\n📝 Log saved to: {log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc353229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd4489",
   "metadata": {},
   "source": [
    "### Define Cleaning Functions (Q1–Q5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f1acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_orders_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Take a raw orders DataFrame and return a fully cleaned version.\n",
    "    This now includes Q1–Q10:\n",
    "    - Dates, prices, ratings, locations, booleans\n",
    "    - Category mapping, delivery_days cleaning\n",
    "    - Duplicate handling, price outliers, payment method\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Q1: dates\n",
    "    df = standardize_order_date(df, col=\"order_date\")\n",
    "\n",
    "    # Q2: prices\n",
    "    df = clean_price_column(df, col=\"original_price_inr\")\n",
    "\n",
    "    # Q3: ratings\n",
    "    df = clean_customer_rating(df, col=\"customer_rating\")\n",
    "\n",
    "    # Q4: city/state – your actual column names\n",
    "    df = standardize_location(\n",
    "        df,\n",
    "        city_col=\"customer_city\",\n",
    "        state_col=\"customer_state\",\n",
    "    )\n",
    "\n",
    "    # Q5: booleans – your actual boolean-like columns\n",
    "    boolean_cols = [\n",
    "        \"is_prime_member\",\n",
    "        \"is_festival_sale\",\n",
    "        \"is_prime_eligible\",\n",
    "    ]\n",
    "    df = normalize_boolean_columns(df, boolean_cols)\n",
    "\n",
    "    # Q6: category mapping\n",
    "    df = clean_category(df, col=\"category\")\n",
    "\n",
    "    # Q7: delivery_days cleaning\n",
    "    df = clean_delivery_days(df, col=\"delivery_days\")\n",
    "\n",
    "    # Q8: remove duplicate transaction_ids (just in case)\n",
    "    if \"transaction_id\" in df.columns:\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates(subset=\"transaction_id\")\n",
    "        after = len(df)\n",
    "        print(f\"[Q8] Dropped {before - after} duplicate rows based on transaction_id.\")\n",
    "\n",
    "    # Q9: handle price outliers\n",
    "    df = handle_price_outliers(df, col=\"original_price_inr\")\n",
    "\n",
    "    # Q10: payment_method standardization\n",
    "    df = clean_payment_method(df, col=\"payment_method\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f8c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working folder: c:\\Users\\DELL\\Desktop\\amazon_project\\notebooks\n",
      "Contents here:\n",
      "[WindowsPath('01_data_understanding.ipynb'), WindowsPath('02_data_cleaning_part1.ipynb'), WindowsPath('03_eda_overview.ipynb'), WindowsPath('04_final_report.html'), WindowsPath('04_final_report.ipynb')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Current working folder:\", os.getcwd())\n",
    "print(\"Contents here:\")\n",
    "print(list(Path(\".\").iterdir()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12499c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_india_2015.csv\n",
      "amazon_india_2016.csv\n",
      "amazon_india_2017.csv\n",
      "amazon_india_2018.csv\n",
      "amazon_india_2019.csv\n",
      "amazon_india_2020.csv\n",
      "amazon_india_2021.csv\n",
      "amazon_india_2022.csv\n",
      "amazon_india_2023.csv\n",
      "amazon_india_2024.csv\n",
      "amazon_india_2025.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_raw_dir = Path(\"../data_raw\")\n",
    "for f in data_raw_dir.iterdir():\n",
    "    print(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61910d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>is_festival_sale</th>\n",
       "      <th>festival_name</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>return_status</th>\n",
       "      <th>order_month</th>\n",
       "      <th>order_year</th>\n",
       "      <th>order_quarter</th>\n",
       "      <th>product_weight_kg</th>\n",
       "      <th>is_prime_eligible</th>\n",
       "      <th>product_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_2015_00000001</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>CUST_2015_00003884</td>\n",
       "      <td>PROD_000021</td>\n",
       "      <td>Samsung Galaxy S6 16GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>123614.29</td>\n",
       "      <td>27.91</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>True</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_2015_00000002</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>CUST_2015_00011709</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_2015_00000003</td>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>CUST_2015_00004782</td>\n",
       "      <td>PROD_000039</td>\n",
       "      <td>Samsung Galaxy Note 5 64GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>97644.25</td>\n",
       "      <td>46.93</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_2015_00000004</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>CUST_2015_00008105</td>\n",
       "      <td>PROD_000085</td>\n",
       "      <td>Motorola Moto G (3rd Gen) 16GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Motorola</td>\n",
       "      <td>21,947.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>True</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_2015_00000005</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>CUST_2015_00002955</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id  order_date         customer_id   product_id  \\\n",
       "0  TXN_2015_00000001  2015-01-25  CUST_2015_00003884  PROD_000021   \n",
       "1  TXN_2015_00000002  2015-01-05  CUST_2015_00011709  PROD_000055   \n",
       "2  TXN_2015_00000003  2015-01-24  CUST_2015_00004782  PROD_000039   \n",
       "3  TXN_2015_00000004  2015-01-28  CUST_2015_00008105  PROD_000085   \n",
       "4  TXN_2015_00000005  2015-01-31  CUST_2015_00002955  PROD_000055   \n",
       "\n",
       "                           product_name     category  subcategory     brand  \\\n",
       "0          Samsung Galaxy S6 16GB Black  Electronics  Smartphones   Samsung   \n",
       "1          OnePlus OnePlus 2 16GB White  Electronics  Smartphones   OnePlus   \n",
       "2      Samsung Galaxy Note 5 64GB Black  Electronics  Smartphones   Samsung   \n",
       "3  Motorola Moto G (3rd Gen) 16GB Black  Electronics  Smartphones  Motorola   \n",
       "4          OnePlus OnePlus 2 16GB White  Electronics  Smartphones   OnePlus   \n",
       "\n",
       "  original_price_inr  discount_percent  ...  is_festival_sale  \\\n",
       "0          123614.29             27.91  ...              True   \n",
       "1           54731.86              0.00  ...             False   \n",
       "2           97644.25             46.93  ...              True   \n",
       "3          21,947.26              0.00  ...             False   \n",
       "4           54731.86              0.00  ...             FALSE   \n",
       "\n",
       "       festival_name  customer_rating  return_status  order_month order_year  \\\n",
       "0  Republic Day Sale              5.0      Delivered            1       2015   \n",
       "1                NaN              4.5      Delivered            1       2015   \n",
       "2  Republic Day Sale              NaN      Delivered            1       2015   \n",
       "3                NaN              3.0      Delivered            1       2015   \n",
       "4                NaN              4.0      Delivered            1       2015   \n",
       "\n",
       "  order_quarter product_weight_kg is_prime_eligible product_rating  \n",
       "0             1              0.19              True            4.7  \n",
       "1             1              0.20              True            4.1  \n",
       "2             1              0.17              True            3.3  \n",
       "3             1              0.22              True            3.5  \n",
       "4             1              0.20              True            4.1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "raw_path = Path(\"../data_raw/amazon_india_2015.csv\")  # using correct path\n",
    "df_raw = pd.read_csv(raw_path)\n",
    "\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0af8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>is_festival_sale</th>\n",
       "      <th>festival_name</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>return_status</th>\n",
       "      <th>order_month</th>\n",
       "      <th>order_year</th>\n",
       "      <th>order_quarter</th>\n",
       "      <th>product_weight_kg</th>\n",
       "      <th>is_prime_eligible</th>\n",
       "      <th>product_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_2015_00000001</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>CUST_2015_00003884</td>\n",
       "      <td>PROD_000021</td>\n",
       "      <td>Samsung Galaxy S6 16GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>123614.29</td>\n",
       "      <td>27.91</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>True</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_2015_00000002</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>CUST_2015_00011709</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_2015_00000003</td>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>CUST_2015_00004782</td>\n",
       "      <td>PROD_000039</td>\n",
       "      <td>Samsung Galaxy Note 5 64GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>97644.25</td>\n",
       "      <td>46.93</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_2015_00000004</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>CUST_2015_00008105</td>\n",
       "      <td>PROD_000085</td>\n",
       "      <td>Motorola Moto G (3rd Gen) 16GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Motorola</td>\n",
       "      <td>21947.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>True</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_2015_00000005</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>CUST_2015_00002955</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id order_date         customer_id   product_id  \\\n",
       "0  TXN_2015_00000001 2015-01-25  CUST_2015_00003884  PROD_000021   \n",
       "1  TXN_2015_00000002 2015-05-01  CUST_2015_00011709  PROD_000055   \n",
       "2  TXN_2015_00000003 2015-01-24  CUST_2015_00004782  PROD_000039   \n",
       "3  TXN_2015_00000004 2015-01-28  CUST_2015_00008105  PROD_000085   \n",
       "4  TXN_2015_00000005 2015-01-31  CUST_2015_00002955  PROD_000055   \n",
       "\n",
       "                           product_name     category  subcategory     brand  \\\n",
       "0          Samsung Galaxy S6 16GB Black  Electronics  Smartphones   Samsung   \n",
       "1          OnePlus OnePlus 2 16GB White  Electronics  Smartphones   OnePlus   \n",
       "2      Samsung Galaxy Note 5 64GB Black  Electronics  Smartphones   Samsung   \n",
       "3  Motorola Moto G (3rd Gen) 16GB Black  Electronics  Smartphones  Motorola   \n",
       "4          OnePlus OnePlus 2 16GB White  Electronics  Smartphones   OnePlus   \n",
       "\n",
       "   original_price_inr  discount_percent  ...  is_festival_sale  \\\n",
       "0           123614.29             27.91  ...              True   \n",
       "1            54731.86              0.00  ...             False   \n",
       "2            97644.25             46.93  ...              True   \n",
       "3            21947.26              0.00  ...             False   \n",
       "4            54731.86              0.00  ...             FALSE   \n",
       "\n",
       "       festival_name  customer_rating  return_status  order_month order_year  \\\n",
       "0  Republic Day Sale              5.0      Delivered            1       2015   \n",
       "1                NaN              4.5      Delivered            1       2015   \n",
       "2  Republic Day Sale              NaN      Delivered            1       2015   \n",
       "3                NaN              3.0      Delivered            1       2015   \n",
       "4                NaN              4.0      Delivered            1       2015   \n",
       "\n",
       "  order_quarter product_weight_kg is_prime_eligible product_rating  \n",
       "0             1              0.19              True            4.7  \n",
       "1             1              0.20              True            4.1  \n",
       "2             1              0.17              True            3.3  \n",
       "3             1              0.22              True            3.5  \n",
       "4             1              0.20              True            4.1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = clean_orders(df_raw)\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f5eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33165 entries, 0 to 33164\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   transaction_id          33165 non-null  object        \n",
      " 1   order_date              33165 non-null  datetime64[ns]\n",
      " 2   customer_id             33165 non-null  object        \n",
      " 3   product_id              33165 non-null  object        \n",
      " 4   product_name            33165 non-null  object        \n",
      " 5   category                33165 non-null  object        \n",
      " 6   subcategory             33165 non-null  object        \n",
      " 7   brand                   33165 non-null  object        \n",
      " 8   original_price_inr      33165 non-null  Float64       \n",
      " 9   discount_percent        33165 non-null  float64       \n",
      " 10  discounted_price_inr    33165 non-null  float64       \n",
      " 11  quantity                33165 non-null  int64         \n",
      " 12  subtotal_inr            33165 non-null  float64       \n",
      " 13  delivery_charges        30511 non-null  float64       \n",
      " 14  final_amount_inr        33165 non-null  float64       \n",
      " 15  customer_city           33165 non-null  object        \n",
      " 16  customer_state          33165 non-null  object        \n",
      " 17  customer_tier           33165 non-null  object        \n",
      " 18  customer_spending_tier  33165 non-null  object        \n",
      " 19  customer_age_group      29189 non-null  object        \n",
      " 20  payment_method          33165 non-null  object        \n",
      " 21  delivery_days           33165 non-null  object        \n",
      " 22  delivery_type           33165 non-null  object        \n",
      " 23  is_prime_member         33165 non-null  object        \n",
      " 24  is_festival_sale        33165 non-null  object        \n",
      " 25  festival_name           10584 non-null  object        \n",
      " 26  customer_rating         21517 non-null  float64       \n",
      " 27  return_status           33165 non-null  object        \n",
      " 28  order_month             33165 non-null  int64         \n",
      " 29  order_year              33165 non-null  int64         \n",
      " 30  order_quarter           33165 non-null  int64         \n",
      " 31  product_weight_kg       33165 non-null  float64       \n",
      " 32  is_prime_eligible       33165 non-null  object        \n",
      " 33  product_rating          33165 non-null  float64       \n",
      "dtypes: Float64(1), datetime64[ns](1), float64(8), int64(4), object(20)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442d5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33165 entries, 0 to 33164\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   transaction_id          33165 non-null  object        \n",
      " 1   order_date              33165 non-null  datetime64[ns]\n",
      " 2   customer_id             33165 non-null  object        \n",
      " 3   product_id              33165 non-null  object        \n",
      " 4   product_name            33165 non-null  object        \n",
      " 5   category                33165 non-null  object        \n",
      " 6   subcategory             33165 non-null  object        \n",
      " 7   brand                   33165 non-null  object        \n",
      " 8   original_price_inr      33165 non-null  Float64       \n",
      " 9   discount_percent        33165 non-null  float64       \n",
      " 10  discounted_price_inr    33165 non-null  float64       \n",
      " 11  quantity                33165 non-null  int64         \n",
      " 12  subtotal_inr            33165 non-null  float64       \n",
      " 13  delivery_charges        30511 non-null  float64       \n",
      " 14  final_amount_inr        33165 non-null  float64       \n",
      " 15  customer_city           33165 non-null  string        \n",
      " 16  customer_state          33165 non-null  string        \n",
      " 17  customer_tier           33165 non-null  object        \n",
      " 18  customer_spending_tier  33165 non-null  object        \n",
      " 19  customer_age_group      29189 non-null  object        \n",
      " 20  payment_method          33165 non-null  object        \n",
      " 21  delivery_days           33165 non-null  object        \n",
      " 22  delivery_type           33165 non-null  object        \n",
      " 23  is_prime_member         33165 non-null  boolean       \n",
      " 24  is_festival_sale        33165 non-null  boolean       \n",
      " 25  festival_name           10584 non-null  object        \n",
      " 26  customer_rating         21517 non-null  float64       \n",
      " 27  return_status           33165 non-null  object        \n",
      " 28  order_month             33165 non-null  int64         \n",
      " 29  order_year              33165 non-null  int64         \n",
      " 30  order_quarter           33165 non-null  int64         \n",
      " 31  product_weight_kg       33165 non-null  float64       \n",
      " 32  is_prime_eligible       33165 non-null  boolean       \n",
      " 33  product_rating          33165 non-null  float64       \n",
      "dtypes: Float64(1), boolean(3), datetime64[ns](1), float64(8), int64(4), object(15), string(2)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean = clean_orders_df(df_raw)\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9384e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ..\\data_cleaned\\amazon_india_2015_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"../data_cleaned/amazon_india_2015_cleaned.csv\")\n",
    "df_clean.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8997b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"../data_cleaned_v2\").mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55750d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning → amazon_india_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2015_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2016_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2017_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2018_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2019_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2020_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2021_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2022_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2023_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2024_cleaned_v2.csv\n",
      "\n",
      "Cleaning → amazon_india_2025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved → ..\\data_cleaned_v2\\amazon_india_2025_cleaned_v2.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "raw_dir = Path(\"../data_raw\")\n",
    "clean_dir = Path(\"../data_cleaned_v2\")\n",
    "\n",
    "for file in raw_dir.iterdir():\n",
    "    if file.suffix == \".csv\":\n",
    "        print(f\"Cleaning → {file.name}\")\n",
    "        \n",
    "        # Load raw file\n",
    "        df_raw = pd.read_csv(file)\n",
    "        \n",
    "        # Clean using our pipeline\n",
    "        df_clean = clean_orders_df(df_raw)\n",
    "        \n",
    "        # Create output file name\n",
    "        out_path = clean_dir / file.name.replace(\".csv\", \"_cleaned_v2.csv\")\n",
    "        \n",
    "        # Save cleaned file\n",
    "        df_clean.to_csv(out_path, index=False)\n",
    "        \n",
    "        print(f\"✔ Saved → {out_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e959d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronics', 'ELECTRONICS', 'Electronicss',\n",
       "       'Electronics & Accessories', 'Electronic'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['category'].unique()[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df764029",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    \"electronics\": \"Electronics\",\n",
    "    \"electronic\": \"Electronics\",\n",
    "    \"electronicss\": \"Electronics\",\n",
    "    \"electronics & accessories\": \"Electronics\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a3c169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_category(df: pd.DataFrame, col: str = \"category\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert to lowercase for easier matching\n",
    "    s = df[col].astype(\"string\").str.strip().str.lower()\n",
    "    \n",
    "    category_map = {\n",
    "        \"electronics\": \"Electronics\",\n",
    "        \"electronic\": \"Electronics\",\n",
    "        \"electronicss\": \"Electronics\",\n",
    "        \"electronics & accessories\": \"Electronics\",\n",
    "    }\n",
    "    \n",
    "    df[col] = s.replace(category_map)\n",
    "    \n",
    "    # Convert back to title case formatting\n",
    "    df[col] = df[col].str.title()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db05f62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['Electronics']\n",
       "Length: 1, dtype: string"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = clean_category(df_clean)\n",
    "df_clean['category'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24febe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '2', '1', '5', '6', '4', '0', '-1', '1-2 days', '7',\n",
       "       'Same Day', 'Express', '15'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"delivery_days\"].unique()[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f710203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_delivery_days(df: pd.DataFrame, col: str = \"delivery_days\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean delivery_days column and convert to numeric days.\n",
    "    Examples:\n",
    "      \"3\" -> 3\n",
    "      \"1-2 days\" -> 2\n",
    "      \"Same Day\" -> 0\n",
    "      \"Express\" -> 1\n",
    "      \"-1\" -> NaN\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    s = df[col].astype(\"string\").str.strip()\n",
    "\n",
    "    def parse_delivery(val):\n",
    "        if val is None or pd.isna(val) or val == \"\":\n",
    "            return pd.NA\n",
    "\n",
    "        v = val.lower().strip()\n",
    "\n",
    "        # Same day / express keywords\n",
    "        if v in (\"same day\", \"sameday\"):\n",
    "            return 0\n",
    "        if v == \"express\":\n",
    "            return 1  # assume delivered within 1 day\n",
    "\n",
    "        # Remove the word \"days\" / \"day\"\n",
    "        v = v.replace(\"days\", \"\").replace(\"day\", \"\").strip()\n",
    "\n",
    "        # Handle ranges like \"1-2\"\n",
    "        if \"-\" in v:\n",
    "            parts = v.split(\"-\")\n",
    "            nums = []\n",
    "            for p in parts:\n",
    "                p = p.strip()\n",
    "                try:\n",
    "                    nums.append(float(p))\n",
    "                except:\n",
    "                    pass\n",
    "            if nums:\n",
    "                # take the max in the range, e.g. 1-2 -> 2\n",
    "                val_num = max(nums)\n",
    "                if val_num >= 0:\n",
    "                    return val_num\n",
    "                else:\n",
    "                    return pd.NA\n",
    "\n",
    "        # Handle simple numbers like \"3\", \"0\", \"-1\"\n",
    "        try:\n",
    "            n = float(v)\n",
    "            if n < 0:\n",
    "                return pd.NA\n",
    "            return n\n",
    "        except:\n",
    "            return pd.NA\n",
    "\n",
    "    df[col] = s.map(parse_delivery).astype(\"Float64\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6ff8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<FloatingArray>\n",
       " [3.0, 2.0, 1.0, 5.0, 6.0, 4.0, 0.0, 7.0, 15.0]\n",
       " Length: 9, dtype: Float64,\n",
       " Float64Dtype())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = clean_delivery_days(df_clean, \"delivery_days\")\n",
    "df_clean[\"delivery_days\"].unique(), df_clean[\"delivery_days\"].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f0885b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.duplicated(subset=\"transaction_id\").sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1656003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          77385.0\n",
       "mean       60163.93598\n",
       "std      311401.670915\n",
       "min         -239246.47\n",
       "25%           21351.47\n",
       "50%           31831.49\n",
       "75%           63597.67\n",
       "max         23751352.0\n",
       "Name: original_price_inr, dtype: Float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"original_price_inr\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ac8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_price_outliers(\n",
    "    df: pd.DataFrame,\n",
    "    col: str = \"original_price_inr\",\n",
    "    lower_bound: float = 0.0,\n",
    "    upper_quantile: float = 0.99,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle extreme values in price column.\n",
    "    - Any value <= lower_bound becomes NaN\n",
    "    - Any very high value is capped at the given upper quantile\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    s = df[col].astype(\"Float64\")\n",
    "\n",
    "    # 1) Remove clearly invalid (negative / zero if we want)\n",
    "    s = s.mask(s <= lower_bound, other=pd.NA)\n",
    "\n",
    "    # 2) Compute upper cap from remaining positive values\n",
    "    positive = s.dropna()\n",
    "    if len(positive) == 0:\n",
    "        df[col] = s\n",
    "        return df\n",
    "\n",
    "    cap = positive.quantile(upper_quantile)\n",
    "\n",
    "    # 3) Clip prices above cap\n",
    "    s = s.clip(upper=cap)\n",
    "\n",
    "    df[col] = s\n",
    "\n",
    "    print(f\"[{col}] Applied outlier handling: <= {lower_bound} set to NaN, values above {cap:.2f} capped.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "585e2f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 220917.55 capped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count         77179.0\n",
       "mean     48796.612505\n",
       "std      40818.096885\n",
       "min           1067.27\n",
       "25%          21443.85\n",
       "50%          31880.98\n",
       "75%           63788.0\n",
       "max         220917.55\n",
       "Name: original_price_inr, dtype: Float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = handle_price_outliers(df_clean, \"original_price_inr\")\n",
    "df_clean[\"original_price_inr\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16c3a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_payment_method(df: pd.DataFrame, col: str = \"payment_method\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize payment_method values into a few categories:\n",
    "    COD, Card, UPI, Net Banking, Wallet, EMI, Other\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    s = df[col].astype(\"string\").str.strip().str.lower()\n",
    "\n",
    "    def normalize(pm: str):\n",
    "        if pm is None or pd.isna(pm) or pm == \"\":\n",
    "            return \"Other\"\n",
    "\n",
    "        text = pm.lower()\n",
    "\n",
    "        # COD / Cash on Delivery\n",
    "        if \"cod\" in text or \"cash on delivery\" in text or text == \"cash\":\n",
    "            return \"COD\"\n",
    "\n",
    "        # UPI (GPay, PhonePe, BHIM, etc.)\n",
    "        if \"upi\" in text or \"gpay\" in text or \"google pay\" in text or \"phonepe\" in text or \"bhim\" in text:\n",
    "            return \"UPI\"\n",
    "\n",
    "        # Cards\n",
    "        if \"credit card\" in text or \"debit card\" in text or \"card\" in text:\n",
    "            return \"Card\"\n",
    "\n",
    "        # Net Banking\n",
    "        if \"net banking\" in text or \"netbanking\" in text or \"internet banking\" in text:\n",
    "            return \"Net Banking\"\n",
    "\n",
    "        # Wallets (Paytm wallet, Amazon Pay, etc.)\n",
    "        if \"wallet\" in text or \"amazon pay\" in text or \"paytm\" in text:\n",
    "            return \"Wallet\"\n",
    "\n",
    "        # EMI\n",
    "        if \"emi\" in text:\n",
    "            return \"EMI\"\n",
    "\n",
    "        return \"Other\"\n",
    "\n",
    "    df[col] = s.map(normalize).astype(\"string\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c868668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payment_method\n",
       "UPI            46539\n",
       "Card           15511\n",
       "COD             6236\n",
       "Other           5266\n",
       "Net Banking     2285\n",
       "Wallet          1548\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = clean_payment_method(df_clean, \"payment_method\")\n",
    "df_clean[\"payment_method\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4311b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3936\\1424662617.py:15: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 190469.10 capped.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33165 entries, 0 to 33164\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   transaction_id          33165 non-null  object        \n",
      " 1   order_date              33165 non-null  datetime64[ns]\n",
      " 2   customer_id             33165 non-null  object        \n",
      " 3   product_id              33165 non-null  object        \n",
      " 4   product_name            33165 non-null  object        \n",
      " 5   category                33165 non-null  string        \n",
      " 6   subcategory             33165 non-null  object        \n",
      " 7   brand                   33165 non-null  object        \n",
      " 8   original_price_inr      33081 non-null  Float64       \n",
      " 9   discount_percent        33165 non-null  float64       \n",
      " 10  discounted_price_inr    33165 non-null  float64       \n",
      " 11  quantity                33165 non-null  int64         \n",
      " 12  subtotal_inr            33165 non-null  float64       \n",
      " 13  delivery_charges        30511 non-null  float64       \n",
      " 14  final_amount_inr        33165 non-null  float64       \n",
      " 15  customer_city           33165 non-null  string        \n",
      " 16  customer_state          33165 non-null  string        \n",
      " 17  customer_tier           33165 non-null  object        \n",
      " 18  customer_spending_tier  33165 non-null  object        \n",
      " 19  customer_age_group      29189 non-null  object        \n",
      " 20  payment_method          33165 non-null  string        \n",
      " 21  delivery_days           33165 non-null  Float64       \n",
      " 22  delivery_type           33165 non-null  object        \n",
      " 23  is_prime_member         33165 non-null  boolean       \n",
      " 24  is_festival_sale        33165 non-null  boolean       \n",
      " 25  festival_name           10584 non-null  object        \n",
      " 26  customer_rating         21517 non-null  float64       \n",
      " 27  return_status           33165 non-null  object        \n",
      " 28  order_month             33165 non-null  int64         \n",
      " 29  order_year              33165 non-null  int64         \n",
      " 30  order_quarter           33165 non-null  int64         \n",
      " 31  product_weight_kg       33165 non-null  float64       \n",
      " 32  is_prime_eligible       33165 non-null  boolean       \n",
      " 33  product_rating          33165 non-null  float64       \n",
      "dtypes: Float64(2), boolean(3), datetime64[ns](1), float64(8), int64(4), object(12), string(4)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "raw_path = Path(\"../data_raw/amazon_india_2015.csv\")\n",
    "df_raw = pd.read_csv(raw_path)\n",
    "\n",
    "df_clean = clean_orders_df(df_raw)\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daff5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created: C:\\Users\\DELL\\Desktop\\amazon_project\\data_cleaned_v3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "clean_dir = Path(\"../data_cleaned_v3\")\n",
    "clean_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Folder created:\", clean_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1cfc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e698954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df49516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Q1: standardize order_date\n",
    "def standardize_order_date(df: pd.DataFrame, col: str = \"order_date\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    s = df[col].astype(\"string\").str.strip()\n",
    "\n",
    "    def parse_mixed_dates(x):\n",
    "        if x is None or pd.isna(x) or x == \"\":\n",
    "            return pd.NaT\n",
    "        try:\n",
    "            v = float(x)\n",
    "            if v > 20000:\n",
    "                return pd.to_datetime(\"1899-12-30\") + pd.to_timedelta(int(v), unit=\"D\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    df[col] = s.map(parse_mixed_dates).astype(\"datetime64[ns]\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q2: clean original_price_inr\n",
    "def clean_price_column(df: pd.DataFrame, col: str = \"original_price_inr\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    s = df[col].astype(\"string\").str.strip()\n",
    "    s = (\n",
    "        s.str.replace(\"₹\", \"\", regex=False)\n",
    "         .str.replace(\"Rs.\", \"\", regex=False)\n",
    "         .str.replace(\"Rs\", \"\", regex=False)\n",
    "         .str.replace(\",\", \"\", regex=False)\n",
    "         .str.replace(\" \", \"\", regex=False)\n",
    "         .str.replace(\"--\", \"\", regex=False)\n",
    "    )\n",
    "    s = s.replace({\"free\": \"0\", \"Free\": \"0\", \"\": np.nan})\n",
    "    df[col] = pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q3: clean customer_rating\n",
    "def clean_customer_rating(df: pd.DataFrame, col: str = \"customer_rating\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    s = df[col].astype(\"string\").str.strip()\n",
    "    s_lower = s.str.lower()\n",
    "\n",
    "    text_map = {\n",
    "        \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "        \"poor\": 1, \"average\": 3, \"good\": 4, \"excellent\": 5\n",
    "    }\n",
    "\n",
    "    def parse_rating(x, x_lower):\n",
    "        if x is None or pd.isna(x) or x == \"\":\n",
    "            return np.nan\n",
    "        if \"⭐\" in x:\n",
    "            c = x.count(\"⭐\")\n",
    "            if 1 <= c <= 5:\n",
    "                return float(c)\n",
    "        if x_lower in text_map:\n",
    "            return float(text_map[x_lower])\n",
    "        try:\n",
    "            v = float(x)\n",
    "            if 0 <= v <= 5:\n",
    "                return v\n",
    "        except:\n",
    "            pass\n",
    "        return np.nan\n",
    "\n",
    "    df[col] = [parse_rating(orig, low) for orig, low in zip(s, s_lower)]\n",
    "    df[col] = df[col].astype(\"float\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q4: standardize city/state\n",
    "def standardize_location(df: pd.DataFrame, city_col=\"customer_city\", state_col=\"customer_state\") -> pd.DataFrame:\n",
    "    def clean_name(series):\n",
    "        series = series.astype(\"string\")\n",
    "        series = series.str.strip()\n",
    "        series = series.str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        series = series.str.title()\n",
    "        return series\n",
    "\n",
    "    if city_col in df.columns:\n",
    "        df[city_col] = clean_name(df[city_col])\n",
    "\n",
    "    if state_col in df.columns:\n",
    "        df[state_col] = clean_name(df[state_col])\n",
    "        state_map = {\n",
    "            \"Up\": \"Uttar Pradesh\",\n",
    "            \"U.P.\": \"Uttar Pradesh\",\n",
    "            \"Delhi\": \"Delhi\",\n",
    "            \"Nct Of Delhi\": \"Delhi\",\n",
    "            \"Mh\": \"Maharashtra\",\n",
    "        }\n",
    "        df[state_col] = df[state_col].replace(state_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q5: normalize boolean-like columns\n",
    "def normalize_boolean_columns(df: pd.DataFrame, cols):\n",
    "    truthy = {\"yes\", \"y\", \"true\", \"t\", \"1\", \"paid\", \"completed\"}\n",
    "    falsy = {\"no\", \"n\", \"false\", \"f\", \"0\", \"unpaid\", \"pending\", \"\"}\n",
    "\n",
    "    df = df.copy()\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        s = df[col].astype(\"string\").str.lower().str.strip()\n",
    "\n",
    "        def to_bool(x):\n",
    "            if x in truthy:\n",
    "                return True\n",
    "            if x in falsy:\n",
    "                return False\n",
    "            return pd.NA\n",
    "\n",
    "        df[col] = s.map(to_bool).astype(\"boolean\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q6: category mapping\n",
    "def clean_category(df: pd.DataFrame, col: str = \"category\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    s = df[col].astype(\"string\").str.strip().str.lower()\n",
    "    \n",
    "    category_map = {\n",
    "        \"electronics\": \"Electronics\",\n",
    "        \"electronic\": \"Electronics\",\n",
    "        \"electronicss\": \"Electronics\",\n",
    "        \"electronics & accessories\": \"Electronics\",\n",
    "    }\n",
    "    \n",
    "    df[col] = s.replace(category_map)\n",
    "    df[col] = df[col].str.title()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Q7: delivery_days cleaning\n",
    "def clean_delivery_days(df: pd.DataFrame, col: str = \"delivery_days\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    s = df[col].astype(\"string\").str.strip()\n",
    "\n",
    "    def parse_delivery(val):\n",
    "        if val is None or pd.isna(val) or val == \"\":\n",
    "            return pd.NA\n",
    "\n",
    "        v = val.lower().strip()\n",
    "\n",
    "        if v in (\"same day\", \"sameday\"):\n",
    "            return 0\n",
    "        if v == \"express\":\n",
    "            return 1\n",
    "\n",
    "        v = v.replace(\"days\", \"\").replace(\"day\", \"\").strip()\n",
    "\n",
    "        if \"-\" in v:\n",
    "            parts = v.split(\"-\")\n",
    "            nums = []\n",
    "            for p in parts:\n",
    "                p = p.strip()\n",
    "                try:\n",
    "                    nums.append(float(p))\n",
    "                except:\n",
    "                    pass\n",
    "            if nums:\n",
    "                val_num = max(nums)\n",
    "                if val_num >= 0:\n",
    "                    return val_num\n",
    "                else:\n",
    "                    return pd.NA\n",
    "\n",
    "        try:\n",
    "            n = float(v)\n",
    "            if n < 0:\n",
    "                return pd.NA\n",
    "            return n\n",
    "        except:\n",
    "            return pd.NA\n",
    "\n",
    "    df[col] = s.map(parse_delivery).astype(\"Float64\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q9: handle price outliers\n",
    "def handle_price_outliers(\n",
    "    df: pd.DataFrame,\n",
    "    col: str = \"original_price_inr\",\n",
    "    lower_bound: float = 0.0,\n",
    "    upper_quantile: float = 0.99,\n",
    ") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    s = df[col].astype(\"Float64\")\n",
    "\n",
    "    s = s.mask(s <= lower_bound, other=pd.NA)\n",
    "\n",
    "    positive = s.dropna()\n",
    "    if len(positive) == 0:\n",
    "        df[col] = s\n",
    "        return df\n",
    "\n",
    "    cap = positive.quantile(upper_quantile)\n",
    "    s = s.clip(upper=cap)\n",
    "\n",
    "    df[col] = s\n",
    "\n",
    "    print(f\"[{col}] Applied outlier handling: <= {lower_bound} set to NaN, values above {cap:.2f} capped.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Q10: payment_method standardization\n",
    "def clean_payment_method(df: pd.DataFrame, col: str = \"payment_method\") -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    s = df[col].astype(\"string\").str.strip().str.lower()\n",
    "\n",
    "    def normalize(pm: str):\n",
    "        if pm is None or pd.isna(pm) or pm == \"\":\n",
    "            return \"Other\"\n",
    "\n",
    "        text = pm.lower()\n",
    "\n",
    "        if \"cod\" in text or \"cash on delivery\" in text or text == \"cash\":\n",
    "            return \"COD\"\n",
    "\n",
    "        if \"upi\" in text or \"gpay\" in text or \"google pay\" in text or \"phonepe\" in text or \"bhim\" in text:\n",
    "            return \"UPI\"\n",
    "\n",
    "        if \"credit card\" in text or \"debit card\" in text or \"card\" in text:\n",
    "            return \"Card\"\n",
    "\n",
    "        if \"net banking\" in text or \"netbanking\" in text or \"internet banking\" in text:\n",
    "            return \"Net Banking\"\n",
    "\n",
    "        if \"wallet\" in text or \"amazon pay\" in text or \"paytm\" in text:\n",
    "            return \"Wallet\"\n",
    "\n",
    "        if \"emi\" in text:\n",
    "            return \"EMI\"\n",
    "\n",
    "        return \"Other\"\n",
    "\n",
    "    df[col] = s.map(normalize).astype(\"string\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# MAIN PIPELINE: Q1–Q10\n",
    "def clean_orders_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Take a raw orders DataFrame and return a fully cleaned version.\n",
    "    Includes Q1–Q10.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Q1\n",
    "    df = standardize_order_date(df, col=\"order_date\")\n",
    "\n",
    "    # Q2\n",
    "    df = clean_price_column(df, col=\"original_price_inr\")\n",
    "\n",
    "    # Q3\n",
    "    df = clean_customer_rating(df, col=\"customer_rating\")\n",
    "\n",
    "    # Q4\n",
    "    df = standardize_location(\n",
    "        df,\n",
    "        city_col=\"customer_city\",\n",
    "        state_col=\"customer_state\",\n",
    "    )\n",
    "\n",
    "    # Q5\n",
    "    boolean_cols = [\n",
    "        \"is_prime_member\",\n",
    "        \"is_festival_sale\",\n",
    "        \"is_prime_eligible\",\n",
    "    ]\n",
    "    df = normalize_boolean_columns(df, boolean_cols)\n",
    "\n",
    "    # Q6\n",
    "    df = clean_category(df, col=\"category\")\n",
    "\n",
    "    # Q7\n",
    "    df = clean_delivery_days(df, col=\"delivery_days\")\n",
    "\n",
    "    # Q8\n",
    "    if \"transaction_id\" in df.columns:\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates(subset=\"transaction_id\")\n",
    "        after = len(df)\n",
    "        print(f\"[Q8] Dropped {before - after} duplicate rows based on transaction_id.\")\n",
    "\n",
    "    # Q9\n",
    "    df = handle_price_outliers(df, col=\"original_price_inr\")\n",
    "\n",
    "    # Q10\n",
    "    df = clean_payment_method(df, col=\"payment_method\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbf553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning → amazon_india_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 190469.10 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2015_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 197037.46 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2016_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 232691.77 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2017_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 243088.52 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2018_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 238553.58 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2019_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 278480.10 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2020_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 293616.38 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2021_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 260015.51 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2022_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 251224.59 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2023_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 245931.55 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2024_cleaned_v3.csv\n",
      "\n",
      "Cleaning → amazon_india_2025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12688\\3600673031.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q8] Dropped 0 duplicate rows based on transaction_id.\n",
      "[original_price_inr] Applied outlier handling: <= 0.0 set to NaN, values above 220917.55 capped.\n",
      "✔ Saved → ..\\data_cleaned_v3\\amazon_india_2025_cleaned_v3.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "raw_dir = Path(\"../data_raw\")\n",
    "clean_dir = Path(\"../data_cleaned_v3\")\n",
    "clean_dir.mkdir(exist_ok=True)  # will create the folder if not there\n",
    "\n",
    "for file in raw_dir.iterdir():\n",
    "    if file.suffix == \".csv\":\n",
    "        print(f\"Cleaning → {file.name}\")\n",
    "        \n",
    "        df_raw = pd.read_csv(file)\n",
    "        df_clean = clean_orders_df(df_raw)   # full Q1–Q10\n",
    "        \n",
    "        out_path = clean_dir / file.name.replace(\".csv\", \"_cleaned_v3.csv\")\n",
    "        df_clean.to_csv(out_path, index=False)\n",
    "        \n",
    "        print(f\"✔ Saved → {out_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
